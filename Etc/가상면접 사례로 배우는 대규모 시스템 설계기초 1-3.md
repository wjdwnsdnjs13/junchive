# 7장 - 분산 시스템을 위한 유일 ID 생성기 설계

## auto_increment
- 분산 환경에서는 AI를 사용할 수 없음.
- 여러 DB 사용 시 지연 시간을 낮추기가 무척 힘들어짐.

### Q) 분산 환경에서 AI가 여러 DB 사용 시 지연 시간을 낮추기 힘든 이유가 무엇인가?

## 1단계 - 문제 이해 및 설계 범위 확정
- 면접의 첫 단계는 적절한 질문을 통해 모호함을 없애야 함.
  - Q) ID의 특성은?
    - A) 유일해야하고, 정렬 가능해야 함.
  - Q) 새로운 레코드의 ID는 항상 1만큼 커야하는가?
    - A) 시간 흐름에 따라 커지지만, 언제나 1 증가한다고 보장은 못 함.
  - Q) ID는 숫자로만 이루어지는가?
    - A) 넹
  - Q) 시스템 규모는 어느정도인가?
    - A) 초당 10_000 ID를 생성할 수 있어야 함.
- 요구사항
  - ID는 유일해야 함.
  - 숫자로만 구성돼야 함
  - 64비트로 표현될 수 있어야 함
  - 발급 날짜에 따라 정렬 가능해야 함
  - 초당 10_000개의 ID를 만들 수 있어야 함

## 2단계 - 개략적 설계안 제시 및 동의 구하기
- 유일성 보장하는 방법
  - 다중 마스터 복제(multi-master replication)
  - UUID(Universally Unique Identifier)
  - 티켓 서버(ticket server)
  - 트위터 스노플레이크(twitter snowflake) 접근법

### 다중 마스터 복제(multi-master replication)
- DB의 auto_increment 기능을 활용하는 것
  - ID 값을 1이 아니라 DB 개수 K 만큼 증가 시킴
- DB 수에 따라 초당 생산 가능 ID 수가 증가함
- 단점
  - 여러 데이터 센터에 걸쳐 규모를 늘리기 어려움
  - ID 유일성은 보장되지만, 시간 흐름에 맞춰 커지는 걸 보장할 수 없다.
  - 서버 추가/제거 시 잘 동작하게 하기 어렵다.

### Q) 시간 흐름에 맞춰 커지는 걸 보장할 수 없는 이유가 무엇인가?

### UUID(Universally Unique Identifier)
- 128비트의 수
- 충돌 가능성이 매우 낮음
  - 중복 UUID가 1개 생길 확률이 50%가 되기 위해서는 초당 10억 개의 UUID를 100년 동안 만들어야 함
- 각 웹 서버가 별도의 ID 생성기를 사용해 독립적으로 ID를 만듦
- 장점
  - 만드는 것은 단순함.
  - 서버 사이 조율이 필요 없어서 동기화 이슈가 없음
  - 각 서버가 자기가 쓸 ID를 직접 만들기 때문에 규모 확장도 쉬움
- 단점
  - 128비트로 길다.
    - 이번 요구 사항은 64비트임.
  - ID를 시간 순으로 정렬할 수 없다
  - ID에 숫자가 아닌 값이 들어올 수 있다.

### 티켓 서버(ticket server)
- 중앙 집중형 티켓 서버 사용
  - auto_increment 기능을 갖춘 티켓 서버를 사용
- 장점
  - 유일성이 보장되는 숫자로만 구성된 ID를 만들기 쉽다.
  - 구현이 쉽고 중소 규모 애플리케이션에서 적합하다.
- 단점
  - 티켓 서버가 SPOF(Single-Point-of-Failure)가 된다.
    - 이를 피하기 위해서는 티켓 서버를 여러 대 사용하면 된다.
      - 데이터 동기화와 같은 새로운 문제가 생길 수 있다.

### 트위터 스노플레이크(twitter snowflake) 접근법
- 트위터에서 사용
- ID의 구조를 여러 절로 분할
  - 사인 비트
    - 현재 사용하지 않지만, 나중을 위해 유보해둔 1비트
  - 타임스탬프
    - 41비트
    - 기원 시각(epoch) 이후로 몇 밀리초 경과했는 지
  - 데이터센터 ID
    - 5비트
    - 32개 데이터센터 사용 가능
  - 서버 ID
    - 5비트
    - 데이터센터 당 32개의 서버 사용 가능
  - 일련 번호
    - 12비트
    - 각 서버에서 ID 생성 마다 일련 번호를 1만큼 증가
    - 1 밀리초 경과 시 마다 0으로 초기화

## 3단계 - 상세 설계
- 데이터 센터 ID와 서버 ID는 시스템 시작 시 결정됨
  - 일반적으로 시스템 운영 중에는 바뀌지 않음.
  - 테이터 센터 ID나 서버 ID를 잘 못 변경하면 ID 충돌이 발생할 수 있음.
- 타임스탬프나 일련번호는 ID 생성기가 동작 중 만들어지는 값

### 타임 스탬프
- 가장 중요한 41비트를 차지함
- 시간 흐름에 따라 정렬 가능
- 이진 표현 형태로부터 UTC 시각을 추출
- 41비트로는 약 69년을 표현할 수 있다.
- 69년이 지난 후에는 기원 시각을 바꾸거나 ID 체계를 마이그레이션 해야함.

### 일련번호
- 12비트
  - 4096개의 값을 가질 수 있음
- 같은 밀리초 동안 하나 이상의 ID를 만든 경우에만 0보다 큰 값을 갖게 됨

## 4단계 - 마무리
- 추가적인 논의 사항
  - 시계 동기화
    - ID가 모두 같은 시계를 사용한다고 가정함.
    - 실제로는 하나의 서버가 여러 코어에서 실행 시 유효하지 않음.
    - 물리적으로 독립된 여러 장비에서 실행 시에도 유효하지 않음.
    - NTP(Network Time Protocol)이 가장 보편적인 수단임.
  - 각 절(section)의 길이 최적화
    - 동시성이 낮고 수명이 긴 애플리케이션인 경우 등과 같은 상황에 대해 처리해야함.
      - 이런 경우 일련 번호를 줄이고 타임스탬프를 늘리는 것이 효과적.
  - 고가용성
    - ID 생성기는 필수 불가결(mission critical) 컴포넌트이므로 아주 높은 가용성을 제공해야 함.
---
# 8장 - URL 간축기 설계

## 1단계 - 문제 이해 및 설계 범위 확정
- 모호함을 줄이고 요구 사항 이끌어 내기
  - Q) URL 단축기가 어떻게 동작해야하는지 예제를 보여줘
    - A) https://www.naver.com/q=asdasd&c=asdasd&v=asdasd 와 같은 입력이 있을 때, https://tinyurl.com/abc1234 와 같은 형태로 변환해야 함.
  - Q) 트래픽 규모는?
    - A) 매일 1억(100million) 개의 URL을 단축해야 함.
  - Q) 단축 URL의 길이는 어느 정도여야 하는가?
    - A) 짧으면 짧을 수록 좋다.
  - Q) 단축 URL에 포함될 문자에 제한이 있는가?
    - A) 단축 URL에는 숫자(0부터 9까지)와 영문자(a부터 z, A부터 Z까지)만 사용 가능
  - Q) 단축 URL을 시스템에서 지우거나 갱신할 수 있는가?
    - A) 시스템을 단순화하기 위해 삭제하거나 갱신 할 수 없다고 가정
- 시스템의 기본적인 기능
  - URL 단축
    - 주어진 긴 URL을 짧게 줄인다
  - URL 리디렉션(redirection)
    - 단축된 URL로 HTTP 요청이 오면 원래 URL로 안내
  - 높은 가용성과 규모 확장성, 장애 감내가 요구됨

### 개략적 추정
- 쓰기 연산
  - 매일 1억 개의 단축 URL 생성
- 초당 쓰기 연산
  - 1억/24/3600 = 1160
- URL 단축 서비스를 10년간 운영한다고 가정하면 1억 * 365 * 10 = 3650억 개의 레코드를 보관해야 함
- 축약 전 URL의 평균 길이는 100이라고 하면
  - 10년 동안 필요한 저장 공간은 3650억 * 100바이트 = 36.5TB

## 2단계 - 개략적 설계안 제시 및 동의 구하기
- API 엔드포인트, URL 리디렉션, URL 단축 플로우에 대해 학습

### API 엔드포인트
- 필요한 엔드포인트
  - URL 단축용 엔드포인트
    - 단축할 URL을 담아서 POST 요청
    - POST /api/v1/data/shorten
    - 인자
      - {longUrl: longURLString}
    - 반환
      - {shortUrl: shortURLString}
  - URL 리디렉션용 엔드포인트
    - 단축된 URL을 받아서 리디렉션
    - GET /api/v1/shortUrl
    - 반환
      - 원래 URL

### URL 리디렉션
- 단축 URL을 받으면 원래 URL로 바꿔서 301 응답의 Location 헤더에 담아 반환
- 301 Permanently Moved
  - 해당 URL에 대한 HTTP 요청의 처리 책임이 **영구적**으로 Location 헤더에 반환된 URL로 이전
  - 영구적으로 이전되었으므로, 브라우저는 이 응답을 **캐시**함
    - 같은 단축 URL 요청 시 브라우저는 ㅐ시된 원래 URL로 요청을 보냄
  - 서버 부하 감소
  - 트래픽 분석이 어려움
- 302 Found
  - 해당 URL에 대한 요청이 **일시적**으로 Location 헤더에 반환된 URL로 이전
  - 항상 단축 URL 서버를 거친 후 원래 URL로 리디렉션\
  - 클릭 발생률이나 발생 위치 추적에 유리
- 해시 테이블을 사용한 구현
  - <단축 URL, 원래 URL> 쌍을 저장
  - 가장 직관적
  - 원래 URL = hashTable.get(단축 URL)
  - 301 또는 302 응답 Location 헤더에 원래 URL을 넣어 전송

### URL 단축
- 긴 URL을 해시 값으로 대응 시킬 해시 함수를 찾아야 함
- 해시 함수가 만족해야 할 요구 사항
  - 입력으로 주어진 긴 URL이 다른 값이면 해시 값도 달라야 한다.
  - 계산된 해시 값은 원래 입력으로 주어졌던 긴 URL로 복원될 수 있어야 한다.

## 3단계 - 상세 설계
### 데이터 모델
- 해시 테이블의 문제점
  - 메모리는 유한하며 비싸다
- <단축 URL, 원래 URL> 쌍을 저장하는 데이터베이스를 사용

### 해시 함수
- 원래 URL을 단축 URL로 변환하는 데 사용

### 해시 값 길이
- 사용할 수 있는 문자
  - [0-9, a-z, A-Z]
  - 10 + 26 + 26 = 62개
  - 62^n >= 3650억 인 n의 최솟값을 찾아야 함
  - 62^6 = 56_800_235_584
  - 62^7 = 3_521_614_606_208
  - 62^8 = 218_340_105_584_896
  - 따라서 hashValue의 길이는 7이 적당함

### 해시 후 충돌 해소
- https://en.wikipedia.ogr/wiki/Systems_design 축약
  - CRC32
    - 5cb54054
  - MD5
    - 5a62509a84df9ee03fe1230b9df8b84e
  - SHA-1
    - 0eeae7916c06853901d9ccbefbfcaf4de57ed85b
- 가장 짧은 CRC32조차도 7자리를 넘음.
  - 해시 값에서 처음 7자만 사용
    - 충돌할 확률 증가
    - 충돌 시 충돌이 해소될 때가지 사전에 정한 문자열을 해시값에 덧붙임
    - 매번 DB 질의가 들어가야 하므로 오버헤드가 큼
    - 블룸 필터를 사용하면 성능을 높일 수 있음

### base-62 변환
- 진법 변환은 URL 단축기를 구현 시 흔히 사용되는 접근법 중 하나
- 수의 표현 방식이 다른 두 시스템이 같은 수를 공유해야하는 경우 유용함
- 62진법을 사용하는 이유는 hashValue에 사용할수 있는 문자가 62개이기 때문

### 해시 후 충돌 해소 vs base-62 변환
해시 후 충돌 해소 | base-62 변환
--- | ---
단축 URL의 길이가 고정됨 | 단축 URL의 길이가 가변적. ID와 비례함
유일성이 보장되는 ID 생성기 불필요 | 유일성 보장 ID 생성기 필요
충돌이 가능해서 충돌 해결 전략 필요 | ID 유일성이 보장되어야 적용 가능하므로 충돌이 없음
ID로부터 단축 URL을 계산하는 것이 아니라 다음 사용 가능한 URL 찾아내는 것 불가능 | ID가 1씩 증가하는 값이라고 가정하면 다음 쓸 수 있는 단축 URL을 찾아낼 수 있음 -> 보안상 문제 가능성

### URL 단축기 상세 설계
1. 입력으로 긴 URL을 받음
2. DB에 해당 URL 검사
3. URL 존재
   - DB의 URL을 반환
4. URL 존재하지 않음
   - 유일한 ID를 생성, DB의 기본 키로 사용
   - 62진법 변환을 적용, ID를 단축 URL로 만듦
   - DB에 저장 후 단축 URL 반환

## 4단계 - 마무리
- 추가적인 논의 사항
  - 처리율 제한 장치
    - 엄청난 양의 URL 단축 요청이 밀려들 경우 무력화될 수 있음.
    - IP 주소 등의 필터링 규칙같은 기능 필요
  - 웹 서버의 규모 확장
    - 웹 계층은 무상태 계층임.
    - 웹 서버를 자유로이 증설하거나 삭제할 수 있음.
  - DB 규모 확장
    - DB를 다중화하거나 샤딩해 규모 확장 가능
  - 데이터 분석 솔루션
    - URL 단축기에 데이터 분석 솔루션을 통합해 정보 분석 가능
  - 가용성, 데이터 일관성, 안정성
    - 대규모 시스템이 성공적으로 운영되기 위해 필수 조건

---
# 9장 - 웹 크롤러 설계
- 웹 크롤러는 로봇 또는 스파이더라 부름
- 검색 엔진에 널리 쓰이는 기술
- 웹에 새로 올라오거나 갱신된 컨텐츠를 찾는 것이 주 목적
  - 콘텐츠란 웹 페이지, 이미지, 비디오, PDF 파일 등을 통틀어서 의미
- 검색 엔진 인덱싱
  - 클로러의 가장 보편적인 용례
  - 웹 페이지를 모아 검색 엔진을 위한 로컬 인덱스를 생성
- 웹 아카이빙
  - 나중에 사용할 목적으로 장기 보관하기 위해 웹에서 정보를 모으는 절차
- 웹 마이닝
  - 유명 금융 기업들이 크롤러를 사용해 주주총회 자료나 연차 보고서 등을 받아 사용
- 웹 모니터링
  - 크롤러 사용 시 저작권이나 상표권이 침해되는 사례 모니터링 가능
- 크롤러의 복잡도는 처리할 데이터 규모에 따라 매우 달라짐.
  - 웹 크롤러가 감당해야 할 데이터의 규모와 기능을 알아내야 함

## 1단계 - 문제 이해 및 설계 범위 확정
- 웹 크롤러의 기본 알고리즘
  - URL 집합이 주어지면, URL이 가리키는 모든 웹 페이지를 다운로드
  - 다운 받은 웹 페이지에서 URL을 추출
  - 추출된 URL들을 다운로드할 URL 목록에 추가하고 위 과정을 처음부터 반복
- 요구 사항에 대한 질의 응답
  - Q) 클롤러의 주된 용도는? 검색 엔진 인덱스 생성, 데이터 마이닝 혹은 그 외의 용도?
    - A) 검색 엔진 인덱스 생성
  - Q) 매 달 얼마나 많은 웹 페이지를 수집해야 하는가?
    - A) 10억 개의 웹 페이지를 수집
  - Q) 새로 만들어진 웹 페이지나 수정된 웹 페이지도 고려하는가?
    - A) 넹
  - Q) 수집한 웹 페이지는 저장하는가?
    - A) 넹. 5년 저장함
  - Q) 중복된 컨텐츠는 어떡하는가?
    - A) 중복된 컨텐츠를 갖는 페이지는 무시해도 됨
- 주의를 기울여야 할 속성
  - 규모 확장성
    - 웹은 거대하므로 병행성(parallelism)을 활용하면 효가적인 웹 크롤링 가능
  - 안정성(robustness)
    - 웹은 함정으로 가득함.
    - 잘못 작성된 HTML서버, 무반응인 서버, 장애/악성 코드가 붙은 링크 등
    - 이런 함정과 비정상적 입력과 환경에 잘 대응해야 함
  - 예절
    - 수집 대상 웹 사이트에 짧은 시간 동안 너무 많은 요청을 보내서는 안됨
  - 확장성
    - 새로운 형태의 컨텐츠를 지원하기 쉬워야 함
    - 기존에 없던 이미지 파일 크롤링을 추가하려고 할 때 전체 시스템을 새로 설계하는 것온 옳지 않음.

### 개략적 규모 추정
- 매달 10억 개의 웹 페이지 다운
- QPS
  - 10억 / 30일 / 24시간 / 3600초 = 약 400페이지/s
- 최대 QPS
  - 2배 정도로 가정
  - 800
- 웹 페이지의 평균 크기는 500k라고 가정
  - 10억 * 500k = 500TB/월
- 5년간 저장
  - 500TB * 12개월 * 5년 = 30PB

## 2단계 - 개략적 설계안 제시 및 동의 구하기
### 시작 URL 집합
- 웹 크롤링의 출발점
- 크롤러가 가능한 많은 링크를 탐색할 수 있도록 하는 URL을 고르는 것이 바람직
- 일반적으로 전체 URL 공간을 작은 부분집합으로 나누는 전략을 사용
- 다른 방법은 주제별로 다른 시작 URL을 사용하는 것
  - 쇼핑, 스포츠, 건강 등

### 미수집 URL 저장소
- 크롤러는 크롤링 상태를 2가지로 관리함
  - 다운로드할 URL
    - 미수집 URL(URL frontier) 저장소라고 부름
      - FIFO Queue라고 생각하면 됨
  - 다운로드된 URL

### HTML 다운로더
- 웹 페이지를 다운로드하는 컴포넌트
- 다운로드 할 페이지는 URL frontier가 제공함

### 도메인 이름 변환기
- 웹 페이지를 다운 받으려면 URL을 IP주소로 변환하는 절차가 필요함
- HTML 다운로더는 도메인 이름 변환기를 사용해 URL에 대응되는 IP 주소를 알아냄

### 콘텐츠 파서
- 다운로드를 위해서는 파싱과 검증 절차를 거쳐야 함
  - 이상한 웹 페이즈는 문제 발생 소지가 있고, 저장 공간을 낭비함
- 크롤링 서버 안에 콘텐츠 파서를 구현 시 크롤링 과정이 느려질 수 있기에 분리.

### 중복 컨텐츠 확인
- 웹에 공개된 연구 결과에 따르면 29% 가량의 웹 페이지 컨텐츠는 중복이라고 함
- HTML 문서의 문자열은 비교하는 것은 비효율적임
  - 효과적인 방법은 웹 페이지 해시 값을 비교하는 것

### 컨텐츠 저장소
- HTML 문서를 보관하는 시스템
- 저장소 구현 시고려할 점
  - 데이터의 유형과 크기
  - 저장소 접근 빈도
  - 데이터의 유효 기간 등
- 디스크와 메모리를 동시에 사용할 예정
  - 대부분의 컨텐츠는 디스크에 저장
  - 인기 있는 컨첸트는 메모리에 둬 접근 지연시간을 감소

### URL 추출기
- HTML 페이지를 파싱해 링크를 추출

### URL 필터
- 특정 컨텐츠 타입이나 파일 확장자를 갖는 URL 접속 오류가 발생하는 URL 등 접근 제외 목록에 포함된 URL을 필터링

### 이미 방문한 URL 처리
- 이미 방문한 URL은 다시 방문하지 않아야 함
- 블룸 필터나 해시 테이블이 널리 사용됨

### URL 저장소
- 이미 방문한 URL을 저장하는 저장소

## 3단계 - 상세 설계
### DFS vs BFS
- 웹은 방향이 있느 ㄴ그래프와 같음
- 페이지 = 노드
- 하이퍼링크(URL) = 엣지
- DFS는 좋지 않을 가능성이 높음
  - 깊이가 어느정도 깊이까지 갈 지 모르기 때문임
- 따라서 웹 크롤러는 보통 BFS를 사용함.
  - BFS는 FIFO Queue를 사용함.
  - FIFO Queue를 사용했을 때의 문제점
    - 한 페이지에서 나오는 링크의 상당수는 같은 서버로 되돌아감.
    - 표준 BFS 알고리즘은 URL 간의 우선순위가 없음.
    - 하지만 실제로는 모든 웹 페이지의 중요성과 품질은 같지 않다.
    - 페이지 rank, 트래픽의 양, 엡데이트 빈도 등의 우선순위가 필요함.

### 미수집 URL 저장소
- **예의**
  - 수집 대상 서버에게 짧은 시간 안에 너무 많은 요청을 보내지 말아야 함.
  - 한 번에 한 페이지만 요청하는 것이 예의다.
  - 웹사이트의 호스트명과 다운로드를 수행하는 작업 스레드 사이의 관계를 유지해 만족할 수 있음.
    - 큐 라우터
      - 같은 호스트에 속한 URL은 언제나 같은 큐로 가도록 보장해줌
    - 매핑 테이블
      - 호스트 이름과 큐 사이의 관계를 보관하는 테이블
    - FIFO Queue
      - 같은 호스트에 속한 URL은 언제나 같은 큐에 보관
    - 큐 선택기
      - 큐들을 순회하면서 큐에서 URL을 꺼내서 해당 큐에서 나온 URL을 다운로드하도록 지정된 작업 스레드에 전달
    - 작업 스레드
      - 전달된 URL을 다운로드하는 작업 수행
      - 작업은 순차처리되며 작업 사이 일정한 지연시간을 둘 수 있다.
- **우선순위**
  - 같은 키워드가 뜨는 페이지라도 서로 다른 중요도를 갖고 있음
    - 페이지랭크, 트래픽 양, 갱신 빈도 등 다양한 척도를 사용할 수 있음.
  - 순위 결정 장치
    - URL을 입력 받아 우선순위를 계산
  - 큐
    - 우선 순위별로 큐가 하나씩 할당
  - 큐 선택기
    - 임의 큐에서 처리할 URL을 꺼내는 역할을 담당함.
- **신선도**
  - 페이지는 수시로 추가/삭제/변경이 일어남.
  - 주기적으로 재수집이 필요함.
    - 웹 페이지의 변경 이력 활용
    - 우선순위를 활용해 중요한 페이지는 더 자주 재수집
- **미수집 URL 저장소를 위한 지속성 저장장치**
  - 크롤러가 처리 할 수 많은 URL을 모두 메모리에 보관하는 것은 옳지 않음.
  - 전부 디스크에 저장하는 것도 성능 병목지점이 될 수 있음.
  - IO 비용을 줄이기 위해 메모리 버퍼에 큐를 두어 주기적으로 디스크에 기록하도록 함.

### HTML 다운로더
- **Robots.txt**
  - 로봇 제외 프로토콜이라고도 부름
  - 이 파일에는 크롤러가 수집해도 되는 페이지 목록이 있음.
  - 크롤러는 이 파일에 나열된 규칙을 먼저 확인해야 함.
- **성능 최적화**
  - **분산 크롤링**
    - 크롤링 작업을 여러 서버에 분산
    - URL 공간을 작은 단위로 분할해 각 서버가 일부를 담당하도록 함.
  - **도메인 이름 변환 결과 캐시**
    - DNS Resolver는 크롤러 성능의 병목 중 하나임
      - DNS 요청을 보내고 결과를 받는 작업의 동기적 특성 때문
    - 크롤러 스레드 가운에 하나라도 이 작업을 수행하면 다른 스레드의 DNS 요청은 전부 블록됨
  - **지역성**
    - 크롤링 작업을 지역별로 분산하는 방법
    - 지역적으로 가까우면 페이지 다운로드 시간이 줄어듦
    - 크롤링 서버, 캐시, 큐, 저장소 등 대부분 컴포넌트에 적용 가능
  - **짧은 타임아웃**
    - 웹 서버가 응답이 느리거나 아예 응답하지 않을 수 있음.
    - 최대 대기 시간을 설정해두어야 함.
- **안정성**
  - 안정 해시
    - 다운로더 서버들에 부하를 분산할 때 사용.
  - 크롤링 상태 및 수집 데이터 저장
    - 장애 발생 시에도 쉽게 복구 할 수 있도록 크롤링 상태와 수집된 데이터를 지속적으로 기록함
  - 예외 처리
    - 에러는 불가피하며 자주 발생함.
    - 예외가 발생해도 전체 시스템이 중단되는 일이 없어야 함.
  - 데이터 검증
    - 시스템 오류를 방지하기 위한 중요 수단 가운데 하나임
- **확장성**
  - 새로운 형태의 콘텐츠를 쉽게 지원할 수 있도록 해야함.
- **문제 있는 컨텐츠 감지 및 회피**
  - 중복 컨텐츠
    - 해시나 체크섬을 사용해 중복 컨텐츠를 탐지
  - 거미 덫(spider trap)
    - 크롤러를 무한 루프에 빠뜨리도록 설계한 웹 페이지임
    - 디렉토리 구조를 무한하게 만드는 등의 덫이 있을 수 있음.
    - 모든 종류의 덫을 피할 수 있는 방법은 없음.
  - 데이터 노이즈
    - 광고나 스크립트 코드, 스팸 같은 URL은 제외해야 함.

## 4단계 - 마무리
- 추가 논의 사항
  - 서버 측 렌더링
    - 많은 웹사이트가 JS나 Ajax 등으로 링크를 즉석에서 만듦
    - 웹 페이지를 그대로 다운 받으면 안됨
    - 서버 사이드 렌더링을 사용하면 해결 가능
  - 원치 않는 페이지 필터링
    - 크롤링에 소요되는 자원은 유한하므로 품질이 떨어지거나 스팸성인 페이지를 걸러낼 수 있도록 해야 함
  - DB 다중화 및 샤딩
    - 다중화와 샤딩 같은 기법을 통해 데이터 계층의 가용성과 규모 확작성, 안정성을 높임
  - 수평적 규모 확장성
    - 대규모 크롤링을 위해서는 수평적 확장이 필요할 수 있음
    - 이를 위해서는 서버가 상태 정보를 유지하지 않는 무상태 서버가 되도록 해야 함
  - 가용성, 일관성, 안정성
    - 성공적인 대형 시스템을 만들기 위해서는 필수로 고려해야할 것들임
  - 데이터 분석 솔루션
    - 데이터를 수집하고 분석하는 것은 매우 중요함