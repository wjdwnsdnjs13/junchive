# 5장 - 지표 모니터링 및 경보 시스템
## 1단계 - 문제 이해 및 설계 범위 확정
- 설계 범위 확정
  - Q) 시스템의 사용자는 누구인가, 대형 IT 업체 회사 내부 시스템인지, 데이터독 같은 SaaS 서비스인지?
    - A) 회사 내부 시스템임
  - Q) 어떤 지표를 수집해야 하는가?
    - A) 시스템 운영 지표(operational system metrics)를 수집.
      - CPU 부하, 메모리 사용률, 디스크 사용량 같은 저수준의 운영체제 사용률 지표
      - 서버가 처리하는 초당 요청 수(requests per second)
      - 사업 지표(business metrics)는 제외함.
  - Q) 모니터링할 인프라 규모는?
    - A) DAU는 1억, 1000개의 서버 풀이 있고 풀마다 100개의 서버 하드웨어를 유지함
  - Q) 지표 데이터 보관 기간은?
    - A) 1년 간 보관
  - Q) 장기 보관 시 지표의 해상도를 낮춰도 되는가?
    - A) 새로 수집한 데이터는 7일 보관, 7일 뒤에는 1분 단위 데이터로 30일 보관, 이후에는 1시간 단위 데이터로 변환해서 보관
  - Q) 경보 채널로 지원하는 것은?
    - A) 이메일, 전화, 페이저듀티, 웹훅 등을 지원
  - Q) 에러 로그나 액세스 로그 등에 대한 수집 기능도 필요한가?
    - A) 노
  - Q) 분산 시스템 추적(distributed system tracing)을 지원해야 하는가?
    - A) 노

### 개략적 요구사항 및 가정
- 대규모 인프라를 모니터링 함
  - DAU 1억
  - 서버 풀 1000개, 풀 당 서버 수 100개, 서버 당 100개의 운영 지표 수집.
    - 모니터링 해야하는 지표의 수는 천만 개 수준
  - 데이터 보관 기간은 1년
  - 수집한 그대로 데이터를 일주일간 보관, 7일 이후에는 1분 단위 데이터로 30일간 보관, 30일 이후에는 1시간 단위 데이터로 보관
- 모니터링할 지표
  - CPU 사용률
  - 요청 수
  - 메모리 사용량
  - 메시지 큐 내의 메시지 수

### 비기능 요구사항
- 규모 확장성
- 낮은 응답 지연
- 안정성
- 유연성
  - 기술 변화에 따라 새로운 기술을 쉽게 통합할 수 있게 유연하고 변경 가능한 파이프라인을 이용해 구축


- 고려하지 않아도 되는 요구사항
  - 엘라스틱서치, 로그스태시, 키바나 등과 같은 로그 모니터링 시스템
  - 분산 시스템 추적
    - 서비스에 대한 요청이 분산 시스템 내부를 어떻게 흘러 다니는지 추적할 수 있는 시스템
    - 요청이 한 서비스에서 다른 서비스로 이동할 때마다 데이터를 수집


## 2단계 - 개략적 설계안 제시 및 동의 구하기
### 기본적 사항
- 데이터 수집
- 데이터 전송
- 데이터 저장소
- 경보
- 시각화

### 데이터 모델
- 지표 데이터는 통상 시계열(time series) 데이터 형태로 기록함
  - 값 집합에 타임스탬프가 붙은 형태로 기록한다는 의미
- 시계열에는 고유한 이름이 붙고, 선택적으로 레이블(label)을 붙이기도 함 

### 데이터 접근 패턴
- 쓰기 부하가 막대함
- 읽기 부하는 일시적으로 잠시 치솟았다가 사라짐(spiky)

### 데이터 저장소 시스템
- RDB는 시계열 데이터 읽기 연산에 최적화되어 있지 않음
- NoSQL는 확장이 용이한 스키마를 사용하기 위해서 깊은 지식이 필요함.
- InfluxDB나 프로메테우스 등을 사용

### 개략적 설계안
- 지표 출처
  - 지표 데이터가 만들어지는 곳
  - 애플리케이션 서버, SQL DB, 메시지 큐 등 어떤 것이든 가능
- 지표 수집기
  - 지표 데이터를 수집하고 시계열 데이터에 기록
- 시계열 DB
  - 다량의 시계열 데이터를 분석하고 요약하는데 적합하게 설계된 질의 인터페이스 제공
- 질의 서비스
  - 시계열 DB에 보관된 데이터를 질의하고 가져오는 과정을 돕는 서비스
  - 적합한 시계열 DB를 잘 골랐으면 해당 서비스는 많은 일을 하지 않고, 심지어 필요 없을 수도 있음
- 경보 시스템
  - 경보를 받아야 하는 다양한 대상으로 알림을 전송
- 시각화 시스템
  - 지표를 다양한 형태의 그래프/차트로 시각화하는 기능 제공

## 3단계 - 상세 설계
### 지표 수집
- 카운터나 CPU 사용량 같은 지표를 수집할 때 데이터가 소실되어도 아주 심각한 문제는 아님
- 지표를 보내는 클라는 성공적으로 데이터를 전송했는지 신경 쓰지 않아도 됨

### 지표 수집 - 풀 모델
- 지표 수집기는 데이터를 가져올 서비스 목록을 알아야 함
- '지표 수집기' 서버 내에 모든 서비스 엔드포인트의 DNS/IP 정보를 담은 파일을 두면 간단함
- 서버가 수시로 추가/삭제되는 대규모 운영 환경에서 적합하지 않음.
- etcd나 주키퍼같은 서비스 탐색 기술 사용 시 해결 가능
- 지표 수집 흐름
  - SDS에서 서비스 엔트포인트 설정 메타 데이터 정보를 가져옴
  - 지표 수집기는 사전에 합의된 HTTP 엔드포트에서 지표 데이터를 가져 옴
  - 지표 수집기는 서비스 엔드포인트 목록의 변화를 통지 받기 위한 변경 이벤트 알림 콜백을 서비스 탐색 컴포넌트에 등록할 수 있음.
- 지표 수집기도 분산되어 있어야 함
- 분산되는 것으로 인해 여러 서버가 같은 출처의 데이터를 중복으로 가져오게 될 수 있음
- 한 가지 방법은 안정 해시 링이 있음


### 지표 수집 - 푸시 모델
- 지표 출처에 해당하는 서버가 직접 지표를 수신기에 전송하는 모델
- 모니터링 대상 서버에 통상 수집 에이전트(coasldiont)라는 설치되어 있음
  - 수집 에이전트는 지표 데이터를 수집하고 지표 수신기에 전송
  - 간단한 작업은 처리해서 주는 데이터 집계(aggregation)와 같은 작업은 수집기에 보내는 데이터의 양을 줄이는 데 효과적임
  - 데이터 전송 트래픽 양이 막대해 일시적으로 전송되는 데이터를 처리 못 할 경우 에이전트 내부 소규모 버퍼에 일시적으로 데이터를 보관하고 나중에 재전송 할 수 있음
    - 이 경우 서버 클러스터가 동적으로 서버를 추가하거나 삭제하는 과정에서 데이터가 소실될 수 있음
  - 지표 수집기가 몰려드는 지표 데이터 트래픽을 처리하지 못하는 일을 방지하기 위해서는 지표 수집기 클러스터가 자동 규모 확장이 가능하게 하고, 앞에 로드밸런서를 두는 게 바람직 함

### 풀 모델 vs 푸시 모델
- 풀 모델을 채택한 유명한 사례는 프로메테우스가 있음.
- 푸시 모델을 채택한 유명한 사례는 AWS CloudWatch, Graphite 등이 있음


|         | 풀 모델                                              | 푸시 모델                                           |
|---------|---------------------------------------------------|-------------------------------------------------|
| 손쉬운 디버깅 | 애플리케이션 서버에 /metrics 엔드포인트를 강제해 언제든 지표 데이터를 볼 수 있음 | |                                             |
|상태 진단(Health check) | 애플리케이션 서버가 풀 요청에 응답하지 않으면 해당 서버에 장애 발생으로 진단 가능    | 지표 수집기가 지표를 받지 못하면 원인이 네트워크인지, 서버 장애인지 판단이 어렵다. |
| 생존 기간이 짧은 프로세스 | | 생명 주기가 짧은 프로세스는 지표를 가져각기 전 종료될 수 있음. 푸시 모델은 푸시 게이트웨이를 도입하면 해당 문제를 해결 가능 |
| 방화벽 등의 복잡한 네트워크 구성 | 수집기 서버가 데이터를 긁어가기 위해 /metrics 엔드퐁니트 접근이 되어야 함. 데이터 센터가 여러 개일 경우 문제가 될 수 있음. | 지표 수집기가 로드밸런서 및 자동 규모 확장 클러스터면 어디서든 지표 수집 가능 |
| 성능 | 풀 모델은 일반적으로 TCP를 사용 | 푸시 모델은 보통  UDP를 사용함. |
| 데이터 신빙성 | 지표 데이터를 가져올 애플리케이션 서버 목록이 이미 정의되어 있으므로 믿을 수 있음. | 아무나 지표 수집기에 데이터를 보낼 수 있음. 지표 전송 허용 리스트를 사용하거나 인증을 강제하면 해결 가능 |


### 지표 전송 파이프라인의 규모 확장
- 시계열 DB에 장애가 생기면 데이터 손실이 발생할 수 있.
- 지표 수집기가 지표 데이터를 카프카와 같은 큐 시스템에 전송. 아파치 스톰이나 플링크, 스파크 같은 소비자가 받아서 시계열 DB에 저장
  - 카프카는 고도로 안정되고 규모 확장성이 뛰어난 분산 메시지 플랫폼
  - 데이터 수집 컴포넌트와 처리 컴포넌트 사이의 결합도를 낮춤
  - DB에 장애가 나도 데이터는 소실되지 않음.(카프카에 보관해두면 되기 때문)

### 데이터 집계 지점
- 다양한 지점에서 가능함(수집 에이전트, 수집 파이프라인, 질의 시점 등)
- 수집 에이전트 집계
  - 복잡한 집계 로직 지원은 어려움
- 데이터 수집 파이프라인에서 집계
  - 데이터 기록 전에 집계를 위해서는 플링크 같은 스트림 프로세싱 엔진 필요
  - DB에 계산 결과만 기록해 데이터의 양이 줄어듦
  - 늦게 도착하는 지표 데이터의 처리가 어려움.
  - 원본 데이터를 보관하지 않음
- 질의 시 집계
  - 데이터를 날것 그대로 보관한 후 지르이할 때 필요한 구간에 맞게 집계
  - 질의 처리 시 전체 데이터세트를 대상으로 계산해야하므로 속도가 느림 

### 질의 서비스
- 질의 서버 클러스터 형태로 구현.
- 시계열 DB를 통해 처리하는 역할 담당
- 클라리언트와 시계열 DB 사이의 결합도를 낮춤

### 시계열 DB 질의어
- 프로메테우스나 inFluxDB 같은 지표 모니터링 시스템들은 SQL이 아닌 독자 질의어를 제공함
 
### 저장소 계층 - 저장 용량 최적화
- 데이터를 인코딩하고 압축 시 크기를 매우 줄일 수 있음.
- 타임 스탬프를 전부 저장하는 것이 아니라, 이전 데이터와의 차이를 저장하면 아주 많은 데이터를 줄일 수 있음
- 다운 샘플링
  - 데이터의 해상도를 낮춰 저장.
  - 데이터 보관 기관이 1년이므로, 낡은 데이터는 해상도를 줄이면 됨.
- 냉동 저장소(cold storage)
  - 비활성 상태 데이터를 보관하는 곳

### 보관 시스템
- 경고 처리 흐름
  - 설정 파일을 가져와 캐시 서버에 보관.
    - 경보 규칙은 디스크에 파일 형태로 보관, yaml이 널리 사용됨
  - 경보 관리자는 경보 설정 내역을 캐시에서 가져옴
  - 설정된 규칙에 근거해 경보 관리자가 질의 서비스를 호출.
    - 질의 결과가 설정된 임계값을 넘으면 경보 이벤트가 발생
    - 그 외 경보 필터링, 병합, 중복 제거 등의 작업을 수행함.
    - 접근 제어 : 사람의 실수로 생기는 장애를 막고 시스템의 보안을 유지하기 위해 피요
    - 재시도 : 경보 관리자는 경보 상태를 확인하고 알림이 최소 한 번 전달됨을 보장해야 함
  - 경보 저장소는 카산드라와 같은 key-value 저장소임
    - 모든 경보의 상태가 보관되며, 알림이 적어도 한 번 이상 전달되도록 보장
  - 경보 이벤트는 카프카에 전달
  - 경보 소비자는 카프카에서 경보 이벤트를 읽음
  - 경보 소비자는 카프카에서 읽은 경보 이벤트를 처리해 여러 채널(이메일, Http 서비스 엔드포인트 등)로 알림을 전송

### 시각화 시스템
- 데이터 계층 위에 만들어 짐.
- 지표 대시보드에 다양한 시간 범위로 표시하고 경보와 상태를 표시함

## 4단계 - 마무리
- 요약
  - 지표 데이터 수집 모델
    - 풀 vs 푸시
  - 카프카를 활용한 규모 확장 방안
  - 최적 시계열 DB의 선정
  - 다운샘플링을 통한 데이터 크기 절감
  - 경보/시각화 시스템
    - +@ 구현할 것인가, 구입할 것인가

---
# 6장 - 광고 클릭 이벤트 집계
- 핵심 지표
  - CTR(Click-Through Rate, 클릭률)
  - CVR(Conversion Rate, 전환률)

## 1단계 - 문제 이해 및 설계 범위 확정
- 설계 범위 축소
  - Q) 입력 데이터의 형태는?
    - A) 여러 서버에 분산된 로그 파일. 클릭 이벤트 수집 시 로그 파일 끝에 추가.
  - Q) 데이터의 양은?
    - A) 매일 10억 개의 광고 클릭이 발생, 광고는 200만회 게재. 광고 클릭 이벤트의 수는 매년 30% 증가
  - Q) 가장 중요하게 지원해야 할 질의는?
    - A) 다음 3가지 질의
      - 특정 광고에 대한 지난 M분 간의 클릭 이벤트 수
      - 지난 1분간 가장 많이 클릭된 광고 100개. 질의 기간과 광고 수는 변경 가능. 집계는 매분 이루어짐
      - id, user_id, country 등의 속성을 기준으로 상기 2개 질의 결과 필터링
  - Q) 엣지 케이스에 대한 고려는 어디까지?
    - 예상보다 늦게 도착하는 이벤트
    - 중복된 이벤트
    - 시스템 복구
      - A) 그런 것들도 고려함
  - Q) 지연 시간 조건은?
    - A) 모든 처리가 수 분 내에 이루어져야 함. RTB와 광고 클릭 집계의 지연 시간 조건은 매우 다름.
    - RTB 지연 시간은 요구 사항으로 인해 1초 미만이어야 하지만, 광고 클릭 집계는 수 분 내에 이루어져도 무방함

### 기능 요구 사항
- 지난 M분 동안의 ad_id 클릭 수 집계
- 매분 가장 많이 클릭된 상위 100개 광고 집계
- 다양한 속성에 따른 집계 필터링 지원
- 데이터의 양은 페이스북이나 구글 규모

### 비기능 요구 사항
- 집계 결과 정확성은 RTB 및 광고 과금에 사용되므로 중요함
- 지연되거나 중복된 이벤트를 적절히 처리할 수 있어야 함
- 견고성(reliablility) : 부분 장애는 감내 가능해야 함
- 지연 시간 요구 사항 : 전체 처리 시간은 최대 수 분을 넘지 않아야 함

### 개략적 추정
- DAU는 10억
- 사용자는 하루 평균 한 개의 광고를 클릭한다고 가정
- 광고 클릭 QPS = 10_000
- 최대 광고 클릭 qPS는 5배로 50_000로 가정
- 광고 클릭 이벤트 하나당 0.1KB의 저장 용량이 필요하다고 가정
  - 일일 저장소 요구 사항는 0.1KB * 10억 = 100GB
  - 월간 저장 용량 요구 사항은 3TB

## 2단계 - 개략적 설계안 제시 및 동의 구하기
### 질의 API 설계
- 해당 앱의 클라이어트는 대시 보드를 이용하는 사용자임
- 기능 요구사항
  - 지난 M분 동안 각 ad_i에 발생한 클릭 수 집계
  - 다양한 속성을 기준으로 집계 결과를 필터링하는 기능 지원

### 질의 API 설계 - 지난 M 분 간의 각 ad_id에 발생한 클릭 수 집계
- GET
- /v1/ads/{:ad_id}/aggregated_count
- 주어진 ad_id에 발생한 이벤트 수를 집계해 반환
- 호출 인자
  - from
    - 집계 시작 시간
  - to
    - 집계 종료 시간
  - filter
    - 필터링 전략 식별자
- 응답
  - ad_id
    - 광고 식별자
  - count
    - 집계된 클릭 횟수

### 질의 API 설계 - \M분 간  가장 많이 클릭된 상위 N개 광고 집계
- GET
- /v1/ads/popular
- 지난 M분 동안 가장 많이 클릭된 상위 N개 광고를 집계해 반환
- 호출 인자
  - count
    - 상위 몇 개의 광고를 반환할지 결정
  - window
    - 분 단위로 표현된 집계 윈도우 크기
  - filter
    - 피렅링 전략 식별자
- 응답
  - ad_id
    - 광고 식별자

### 원시 데이터 vs 집계 결과 데이터
|         | 원시 데이터 | 집계 결과 데이터 |
|---------|------------|------------------|
| 장점 | 원본 데이터를 손실 없이 보관. 데이터 필터링 및 재계산 지원 | 데이터 용량 절감, 빠른 질의 성능 |
| 단점 | 막대한 데이터 용량. 낮은 질의 성능 | 데이터 손실. 원본 데이터가 아닌 계산/유도된 데이터를 저장하는 데서 온 결과. ex) 10개의 원본 데이터는 1개의 데이터로 집계되거나 축약될 수 있음 |

- 원시 데이터와 집계 결과 데이터 모두 저장하는 것이 좋음
  - 문제 발생 시 디버깅에 활용 가능.
  - 원시 데이터의 양이 많으므로 직접 질의하는 것은 비효율적임
  - 원시 데이터는 백업 데이터로도 활용됨. 재계산이 아닌 경우 원시 데이터를 질의할 필요 없음. 오래된 원시 데이터는 냉동 저장소로 옮겨 비용 절감
  - 집계 결과 데이터는 활성 데이터 구실을 함. 질의 성능을 위해 튜닝하는 것이 보통

### DB 선택
- 데이터의 모습은? 관계형, 문서, 이진 대형 객체(Binary Large Object, BLOB) 등
- 작업 흐름이 읽기 중심인지, 쓰기 중심인지, 균형인지?
- 트랜잭션을 지원해야 하는지?
- 질의 과정에서 SUM이나 COUNT 같은 온라인 분석 처리(OLAP)가 필요한지?
- 해당 시스템에서는 QPS가 10_000으로 쓰기 비중이 높고 읽기 비중이 낮음
- RDB의 경우 이 정도 규모의 쓰기 연산이 가능하게 구성하기 어려움.
- 카산드라난 InfluxDB 가 적합함

### 개략적 설계안
- 실시간 빅데이터 처리 시 데이터는 보통 무제한으로 시스템에 흘러 들어왔다가 흘러 나감.
- 집계 서비스도 마찬가지, 다만 입력은 원시 데이터(무제한 데이터 스트림), 출력은 집계 결과

### 비동기 처리
- 로그 모니터에서 데이터 집계 서비스로 보내는 것도 메시지 큐를 통해 비동기 처리
- 데이터 집계 서비스에서 결과를 DB에 넣는 것도 메시지 큐를 통해서 비동기 처리
  - 집계 결과를 DB에 바로 기록하지 않는 이유는 정확하게 한 번 데이터를 처리하기 위해(atomic commit, 원자적 커밋) 두 번째 메시지 큐를 사용함

### 집계 서비스
- 맵리듀스(MapReduce)와 같은 분산 처리 프레임워크를 사용해 집계 서비스를 구현
  - 유향 비순환 그래프(Directed Acyclic Graph, DAG)가 좋음
  - 시스템을 맵/집계/리듀스 노드 등 작은 컴퓨팅 단위로 세분화
  - 각 노드는 한 작업만 처리하며, 처리 결과를 다음 노드에 인계

### 집계 서비스 - 맵 노드
