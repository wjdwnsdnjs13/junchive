# 4장 - 처리율 제한 장치의 설계
## 처리율 제한 장치(rate limiter)
- 처리율 제한 장치는 클라이언트나 서비스가 보내는 트래픽의 처리율을 제어하기 위한 장치다.
- HTTP에선 API 요청 횟수가 제한 장치에 정의된 임계치(threshold)를 초과하면 다른 모든 호출은 처리가 중단(block)된다.
  - 사용자는 초당 2회 이상 새 글 생성 불가
  - 같은 ip 주소로 하루 10개의 계정 생성 제한
  - 같은 디바이스 주 5회 이상 리워드 요청 불가

### 처리율 제한 장치의 이점
- DoS 공격에 의한 자원 고갈 방지
- 비용 절감
  - 서버 부하를 줄여 서버 비용을 절감할 수 있다.
  - 제 3자(third-party) API에 사용료를 지불할 경우 매우 중요함.
- 서버 과부하 방지
  - 봇에 의한 트래픽이나 사용자의 잘못된 이용 패턴으로 유발된 트래픽을 걸러낼 수 있음

## 1단계 - 문제 이해 및 설계 범위 확정
- 어떤 종류의 처리율 제한 장치를 만들어야 하는가?
  - 클라이언트 측인지, 서버 측 제한 장치인지?
-> A) 서버측 API를 위한 장치를 설계
- 어떤 기준을 사용해 API 호출을 제한 할 것인가?
  - IP/사용자 ID 또는 다른 기준?
-> A) 다양한 형태의 제어 규칙(throttling rules)를 정의할 수 있는 유연한 시스템
- 시스템 규모는?
  - 스타트업/큰 기업
-> A) 대규모 요청을 처리할 수 있어야함.
- 분산 환경에서 동작하는가?
-> A) 넹
- 처리율 제한 장치는 독립된 서비스인가, 애플리케이션 코드에 포함될 수 있는가?
-> A) 본인 선택
- 사용자의 요청이 limiter에 의해 걸린 경우 사용자에게 알려야 하는가?
-> A) 넹
- 요약된 요청 사항
  - 설정된 처리율을 초과하는 요청은 정확하게 제한
  - 낮은 응답 시간
    - HTTP 응답 시간에 악영향을 주면 안됨
  - 가능한 적은 메모리 사용
  - 분산형 처리율 제한
    - 하나의 limiter를 여러 서버나 프로세스에서 공유 가능
  - 예외 처리
    - 요청이 제한되면 사용자가 알 수 있어야함
  - 높은 내결함
    - limiter에 장애가 생겨도 시스템에는 영향을 주면 안됨

## 2단계 개략적 설계안 제시 및 동의 구하기
- 처리율 제한 장치를 어디에 둘 것인가?
  - 클라/서버 둘 다 가능
  - 클라
    - 안정적이지 못함
    - 위변조가 쉽게 가능
    - 모든 클라의 구현을 통제하는 것이 어려움
  - 서버
    - API 서버 뒤에 위치
    - 클라와 API 서버 사이 미들 웨어로 사용
    - 클라우드 마이크로 서비스에서는 보통 API 게이트웨이라 불리는 컴포넌트에 구현됨
      - API 게이트웨이
        - 처리율 제한, SSL 종단, 사용자 인증, IP 허용 목록 관리 등 지원

- rate limiter 설계 시 중요한 것
  - 서버에 두드냐, 게이트웨이에 두느냐?
    - 회사의 기술 스택과 인력, 목표 등에 따라 매우 달라짐
  - 기술 스택을 점검하고 서버 측 구현을 지원하기 충분한가?
  - 서버 측에서 모든 것을 구현
    - 알고리즘에서 자유로움
  - third-party 게이트웨이 서비스 사용
    - 선택지가 제한적
    - 비용이 들 수 있음
    - 간편함
  - 이미 마이크로서비스에 기반하고 사용자 인증이나 IP 허용 목록 관리 등을 위해 API 게이트웨이가 있다면 게이트웨이에 포함할 수 있음
  - 직접 구현은 시간과 자원이 모소됨

### 처리율 제한 알고리즘
- Token Bucket
  - 토큰 버킷 알고리즘은 토큰을 일정한 속도로 생성하는 버킷에 토큰을 담아두고, 요청이 들어올 때마다 토큰을 소비하는 방식
  - 토큰이 없으면 요청을 거부
  - 인터넷 기업들이 보편적으로 사용
  - 토큰 버킷 알고리즘은 2개의 파라미터를 받음
    - 버킷 크기 : 버킷에 담을 수 있는 최대 토큰의 수
    - 토큰 공급률(refill rate) : 초당 몇 개의 토큰이 버킷에 공금되는지
  - 통상적으로 API 엔드포인트마다 별도의 버킷이 존재.
  - IP 주소에 따른 제한을 적용 시 IP 주소마다 버킷을 할당해야함.
  - 시스템 천제의 처리율을 제한하고 싶다면 모든 요청이 하나의 버킷을 공유하도록 해야 함.
  - 장점
    - 구현이 쉬움
    - 메모리 사용 측면에서도 효율적
    - 짧은 시간 집중되는 트래픽도 처리 가능.
    - 남은 토큰만 있다면 요청이 시스템에 전달됨
  - 단점
    - 버킷 크기와 토큰 공급률이라는 파라미터를 적절하게 튜닝하는 것이 까다로움
    - 트래픽이 갑자기 증가하면 토큰 버킷 알고리즘은 이를 처리할 수 없음
- Leaky Bucket
  - 토큰 버킷과 비슷하지만, 요청 처리율이 고정되어 있음
  - 보통 FIFO 큐로 구현
  - 동작 원리
    - 요청이 도착하면 큐가 pull인지 확인.
    - 빈자리가 잇을 경우 큐에 요청을 추가
    - 큐가 가득 찬 경우 새 요청은 버림.
    - 지정된 시간마다 큐에서 요청을 꺼내 처리
  - 알고리즘이 사용하는 두 파라미터
    - 버킷 크기 : 큐 사이즈와 같은 값으로 큐에서 처리될 항목들이 보관됨
    - 처리율(outflow rate) : 지정된 시간당 몇 개의 항목을 처리할지 지정하는 값, 보통 초 단위로 표현
  - 장점
    - 큐 크기가 제한되어 있어 메모리 사용량 측면에서 효율적
    - 고정된 처리율을 갖고 있기 때문에 안정적 출력(stable outflow rate)이 필요한 경우에 적합
  - 단점
    - 단 시간에 많은 요청이 몰리면 큐에 오래된 요청이 쌓여서 최신 요청들이 버려지게 됨
    - 두 파라미터에 대한 튜닝이 까다로움
- Fixed Window Counter
  - 타임 라인을 고정된 간격의 윈도우로 나누고, 각 윈도우마다 카운터를 붙임
  - 요청이 접수될 대마다 이 카운터의 값은 1씩 증가
  - 카운터 값이 사전에 설정된 임계치에 도달하면 새로운 요청은 새 윈도우가 열릴 때까지 버려짐.
  - 윈도우의 경계 부근에서 순간적으로 많은 트래픽이 집중되면 할당량보다 더 많은 요청이 처리될 수 있다.
  - 장점
    - 메모리 효율이 좋다
    - 이해하기 쉽다
    - 윈도우가 닫히는 시점에 카운터를 초기화하는 방식은 특정한 트래픽 패턴을 처리하기 적합하다
  - 단점
    - 윈도우 경계 부근에서 일시적으로 트래픽이 많이 몰리면 기대했던 처리한도보다 더 많은 요청을 처리하게 됨.
- Sliding Window Log
  - 고정 윈도우 카운터 알고리즘의 경계 부근 트래픽 집중을 해결
  - 동작 원리
    - 요청의 타임스탬프를 추적
      - 타임스탬프 데이터는 보통 레디스의 정렬 집합 같은 캐시에 보관
    - 새 요청이 들어오면 만료된 타임스탬프는 제거.
      - 만료된 타임스탬프 : 그 값이 윈도우의 시작 시점보다 오래된 타임스탬프
    - 새 요청의 타임스탬프를 로그에 추가
    - 로그의 크기가 허용치보다 같거나 작으면 요청을 시스템에 전달. 그렇지 않은 경우에는 처리를 거부
  - 장점
    - 처리율 제한 메커니즘이 아주 정교함
    - 어느 순간의 윈도우를 봐도 허용되는 요청의 개수는 시스템의 처리율 한도를넘지 않음
  - 단점
    - 거부된 요청의 타임스탬프도 보관하기에 다량의 메모리를 사용함
- Sliding Window Counter
  - 고정 윈도우 카운터와 이동 윈도우 로깅 알고리즘을 결합한 것
  - 두 가지 접근법이 사용될 수 있는데, 일단 하나만 설명
  - 요청 수 계산
    - 1분간의 요청 수 + (직전 1분간의 요청 수 * 이동 윈도우와 직전 1분이 겹치는 비율) 
  - 장점
    - 이전 시간대의 평균 처리율에 따라 현재 윈도우의 상태를 계산하므로 짧은 시간에 몰리는 트래픽에도 잘 대응한다
    - 메모리 효율이 좋다
  - 단점
    - 직전 시간대에 도착한 요청이 균등하게 분포되어 있다고 가정한 상태에서 추정치를 계산해서 다소 느슨함
      - 하지만, 클라우드 플레어에서의 실험에 따르면 40억개 중 시스템의 실제 상태와 맞지 않게 허용되거나 버려진 요청은 0.003%에 불과

### 개략적인 아키텍처
- 카운터 값에 따라서 요청을 처리할지 거부할지 결정하는 서비스를 만들어야 함
- DB는 디스크 접근으로 인해서 느리므로 캐시가 바람직함
  - 빠르고 시간에 기반한 만료 정책을 지원
  - 레디스는 INCR와 EXPIRE 두 가지 명령어 지원
    - INCR : 메모리에 저장된 카운터의 값을 1만큼 증가
    - EXPIRE : 카운터의 타임아웃 값을 설정. 설정된 시간이 지나면 카운터는 자동 삭제

## 3단계 - 상세 설계
### 처리율 제한 규칙은 어떻게 만들어지고 어디에 저장되는가?
- 어떤 요청이 한도 제한에 걸리면 API는 429 응답을 클라이언트에게 보낸다.
- 클라이언트가 자신의 요청이 제한에 걸리고 있는지 감지하는 방법
  - HTTP 응답 헤더
    - X-RateLimit-Reamaining : 윈도우 내에 남은 처리 가능 요청의 수
    - X-RateLimit-Limit : 제한된 요청 수
    - X-RateLimit-Retry-After : 한도 제한에 걸리지 않으려면 몇 초 뒤에 요청을 다시 보내야 하는지 알림
- 분산 환경에서의 처리율 제한 장치의 구현
  - 문제점
    - 경쟁 조건(동시성 이슈)
      - 락은 시스템 성능을 상당히 떨어뜨린다는 문제가 있음
      - 루아 스크립트
      - 레디스의 자료 구조 중 하나인 정렬 집합 사용
    - 동기화
      - 여러 대의 처리율 제한 장치를 두게되면 서로 동기화가 필요함
      - 고정 세션
        - 항상 같은 처리율 제한 장치로 요청을 처리
        - 확장도 어렵고 유연하지 않음
      - 레디스 같은 중앙 집중형 데이터 저장소 사용
- 성능 최적화
  - 데이터 센터에서 멀리 떨어진 사용자의 경우 지연 시간이 길어질 수 있음
  - 제한 장치 간의 데이터 동기화 시 최종 일관성 모델을 사용하는 것

## 4단계 - 마무리
- 추가적인 고도화
  - 경성 또는 연성 처리율 제한
    - 경성 처리율 제한
      - 요청의 개수는 임계치를 절대 넘어설 수 없ㅁ다.
    - 연성 처리율 제한
      - 요청 개수는 잠시 동안은 임계치를 넘을 수 있음
    - 다양한 계층에서 처리율 제한
      - 애플리케이션 계층에서만 적용했지만, 다른 계층에서도 가능
      - Iptable을 사용하면 IP 주소에 제한 적용 가능
  - 처리율 제한을 회피하는 방법
    - 클라이언트 측 캐시를 이용해 API 호출 횟수를 줄인다
    - 짧은 시간 너무 많은 메시지를 보내지 않도록 한다
    - 예외나 에러 처리 코드를 도입해 클라가 예외적 상황으로부터 우아하게 복구될 수 있게 한다.
    - 재시도 로직을 구현 시 충분한 백오프 시간을 둔다