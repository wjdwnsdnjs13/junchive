# 3장 - 구글 맵
## 1단계 - 문제 이해 및 설계 범위 확정
- Q) DAU는?
  - A) 10억
- Q) 초점을 맞추는 기능은? e.g)방향 안내, 경로 안내, 예상 도착 시간(Estimated Time of Arrival, ETA) 등
  - A) 위치 갱신, 경로 안내, ETA 등에 초점을 맞춤
- Q) 도로 데이터는 어느 정도 규모인가? 도로 데이터는 있다는 가정 하에 진행하는가?
  - A) 도로 데이터는 다양한 경로로 확보해 두었다고 가정. 수 TB 수준의 가공되지 않은 데이터임.
- Q) 교통 상황도 고려해야 하는가?
  - A) 교통 상황은 도착 시간을 최대한 정확하게 추정하는 데 아주 중요함
- Q) 어떻게 이동하는지도 고려하는가?(이동 수단)
  - A) 다양한 이동 방법을 지원할 수 있어야 함.
- Q) 경로 안내 시 경유지를 여러 곳 설정 가능한가?
  - A) 경유지는 좋지만, 우선은 제외함.
- Q) 사업장 위치 및 사진도 표시해야하는가?
  - A) 사진은 우선 고려하지 않음

### 기능 요구 사항
- 사용자 위치 갱신
- 경로 안내 서비스(ETA 서비스 포함)
- 지도 표시
- 주 지원 단말은 모바일

### 비기능 요구사항 및 제약사항
- 정확도
- 부드러운 경로 표시
- 데이터 및 배터리 사용량
- 일반적으로 널리 통용되는 가용성 및 규모 확장성 요구 만족

### 지도 101 - 측위 시스템
- 측위 시스템은 축을 중심으로 회전하는 구에서 표면 상의 위치를 표현하는 체계
- 위도
  - 주어진 위치가 얼마나 북쪽/남쪽인지
- 경도
  - 얼마나 동쪽/서쪽인지

### 지도 101 - 3차원 위치의 2차원 변환
- 지도 투영법 또는 도법
  - 3차원 구 위의 위치를 2차원 평면에 대응시키는 절차
- 거의 모든 투영법은 실제 지형의 기하학적 특성을 왜곡한다는 공통점을 가짐

### 지도 101 - 지오코딩
- 주소를 지리적 측위 시스템의 좌표로 변환하는 프로세스
  - 서울 서초구 신반포로 194 -> 37.505664, 127.005844
- 주소를 좌표로 변환하는 것을 역지오코딩이라고 함
- 인터폴레이션 등을 사용해 지오코딩 수행 가능
  - GIS(Geographic Information System)와 같은 다양한 시스템이 제공하는 데이터를 결합한다는 의미
  - GIS는 도로망을 지리적 좌표 공간에 대응시키는 방법을 제공하는 여러 시스템 가운데 하나임

### 지도 101 - 지오해싱
- 지도 위 특정 영역을 영문자와 숫자로 구성된 짧은 문자열에 대응시키는 인코딩 체계
  - 2차원의 평면 공간으로 표현된 지리적 영역 위의 격자를 재귀적으로 더 작은 격자로 분할해 나감
- 맵 타일 관리에 지오해싱을 적용함

### 지도 101 - 지도표시
- 간단하게만 다루고 넘어감
- 가장 기본이 되는 개념은 타일
  - 지도를 하나의 이미지로 표시하는 대신 작은 타일로 쪼개어 표시함
  - 클라이언트는 사용자가 보는 영역과 관계된 타일만 다운받아 모자이크처럼 이어 붙인 다음 화면에 뿌림
  - 타일을 가져올 땐 지도 확대 수준에 따라서 가져온다.
    - 전체 지도를 다 보려고 할 때 모든 타일을 가져오는 것이 아니라 전세계를 특정 픽셀로 나타낸 타일 하나만 다운받는 형식

### 지도 101 - 경로 안내 알고리즘을 위한 도로 데이터 처리
- 대부분의 경로 탐색 알고리즘은 다익스트라나 A* 경로 탐색 알고리즘을 활용함
  - 최적의 알고리즘 하나를 고르는 것은 어려우므로 패스함
- 중요한 것은 교차로를 노드, 도로를 노드를 잇는 선으로 표현한다는 것
- 경로 탐색 알고리즘의 성능은 주어진 그래프 크기에 아주 민감함
  - 그래프의 크기가 커질수록 메모리도 많이 필요하고 탐색 시간이 길어짐
  - 지오해싱과 비슷한 방법으로 세계를 작은 격자로 나누고, 격자 안의 도로망을 그래프로 만들어 탐색 범위를 줄이는 방법이 있음
  - 각 격자는 경로 안내 타일(routing tile)이라 부름
  - 각 타일은 도로로 연결된 다른 타일에 대한 참조(reference)를 가지고 있음
  - 이렇게 해야 경로 탐색 알고리즘이 연결된 타일들을 지나갈 때 보일 더 큰 도로망 그래프를 만들어낼 수 있다
- 지도 타일은 PNG 이미지지만, 경로 안내 타일은 도로 데이터로 이루어진 이진 파일(binary file)임

### 지도 101 - 계층적 경로 안내 타일
- 경로 안내가 효과적으로 동작하려면 적정한 수준의 구체성을 갖춘 데이터가 필요함.
  - 너무 세분화된 데이터는 메모리 차지는 물론 너무 많은 시간이 걸릴 수 있음
- 보통 구체성 정도를 상/중/하 정도로 구분해 경로 안내 타일을 준비함
  - 지방도 데이터(local roads) -> 상
  - 더 넓게 규모가 큰 관할구(district)를 잇는 간선 도로(arterial roads) 데이터 -> 중
  - 구체성이 가장 낮은 도시와 도시를 연결하는 주요 고속도로 데이터 -> 하
  - 각 타일에는 다른 정밀도 타일로 연결되는 선(edge)가 있을 수 있음

### 개략적 규모 추정
- 설계 초점이 모바일 단말이므로 데이터 사용량과 배터리 효율을 중요하게 봐야함

### 개략적 규모 추정 - 저장소 사용량
- 저장해야할 데이터
  - 서계 지도
  - 메타데이터(metadata)
    - 각 지도 타일의 메타데이터는 크기가 아주 작아서 무시해도 될 정도이므로 패스함
  - 도로 정보
    - 외부에서 받은 수 TB 용량의 도로 데이터를 안내 타일로 변환
    - 변환 결과의 용량도 비슷할 것이라 예상

### 개략적 규모 추정 - 저장소 사용량 : 세계지도
- 지원하는 확대 수준(zoom level) 별로 지도 타일을 한 벌씩 두어야함
- 타일을 보관하는 데 필요한 용량을 가늠하려면 최대 확대 수준의 필요 타일 개수를 따져보는 것이 좋음
- 지도 확대 마다 4장의 타일로 펼친다고 가정
  - 세계 지도를 4의 제곱형태로 펼치므로 21번 확대하면 4.4조 개의 타일이 필요.
  - 256 * 256 픽셀의 압축 PNG 파일은 한 장에 100KB 정도의 용량이 필요함
  - 4.4조 * 100KB = 440PB
  - 다만, 사람이 살지 않는 지역 등에서는 높은 비율로 압축 가능하므로 80% 이상의 저장 용량을 절감할 수도 있다.
- 모든 수준의 타일을 표현하려면 100PB 정도 필요할 것 같음
  - 최대 수준의 타일을 50PB이라고 가정
  - 50PB + 50PB / 4 + 50PB / 16 + ... = 67PB 
  - 각 수준 별로 저장하는 타일 수는 1/4 수준으로 점점 줄어듦

### 개략적 규모 추정 - 서버 대역폭
- 서버 대역폭 추정을 위해서는 어떤 유형의 요청을 처리해야 하는지 살펴봐야 함
  - 경로 안내 요청
    - 클라가 경로 안내 세션을 시작할 때 전송하는 메시지
    - 사용자가 주 당 35분 사용한다고 가정
    - 주 350억 분, 하루에 50억 분
  - 위치 갱신 요청
    - 경로 안내 진행하는 동안 변경된 사용자 위치를 전송하는 메시지
  - 단순하게 매 초 GPS 좌표를 요청하면 하루 3000억 건의 요청이 발생(50억 분 * 60)
    - 300만 QPS
    - 갱신 요청 주기를 15초나 30초로 하면 QPS를 낮출 수 있음
    - 15초로 할 경우 20만 QPS로 확 줄어듦
      - 최대 QPS는 5배로 가정하면 약 100만 QPS


## 2단계 - 개략적 설계안 제시 및 동의 구하기
### 개략적 설계안 - 위치 서비스
- 클라이언트가 t초마다 위치를 갱신하고 서버에 전송
  - 주기적으로 전송되는 위치 정보 전송의 장점
    - 해당 데이터 스트림을 활용해 시스템을 개선할 수 있음
      - 실시간 교통 상황 모니터링, 새로 만들어진 도로나 폐쇄된 도로 탐지, 행동을 분석해 개인화된 경험 제공에 활용
    - 클라가 보내는 정보는 거의 실시간 정보에 가까워 ETA를 더 정확하게 산출 가능
      - 교통 상황에 따라 경로를 조절할 수도 있음
  - 위치 이력을 클라에서 버퍼링 했다가 일괄 요청(batch request)하면 전송 빈도를 줄일 수 있음
  - 위치 갱신 요청 빈도를 줄여도 여전히 많은 쓰기 작업이 진행됨
    - 많은 쓰기 요청에 최적화되고 규모 확장이 용이한 카산드라 같은 DB가 유용함
    - kafka 같은 스트림 엔진을 통해 처리해야할 수도 있음
- 통신 프로토콜
  - HTTP에서 keep-alive를 함께 사용하면 효율을 높일 수 있음

### 개략적 설계안 - 경로 안내 서비스
- A에서 B까지 합리적으로 가장 빠른 경로를 찾아주는 역할
- 최단 경로일 필요는 없으나, 정확도는 보장되어야 함
- 예시 결과물
```json
{
  'distance': {'text': '0.2mi', 'value': 259},
  'duration': {'text': '1 min1, 'value': 83},
    'end_location': {'lat': 37.4038943, 'Ing': -121.9410454},
    'html_instructions': 'Head <b>northeast</b> on <b>Brandon St</b>...',
    'polyline': {'points': '...'},
    'start_location': {'lat': 37.4027165, 'lng': -121.9435809},
    'geocoded_waypoints': [
      {
        "geocoder_status": "OK",
        "partial_match": true,
        "place_id": "...",
        "types": ["locality", "political"]
      },
      {
        "geocoder_status": "OK",
        "partial_match": true,
        "place_id": "...",
        "types": ["locality", "political"]
      }
    ],
    'travel_mode': 'DRIVING'
  }
```
- 경로 재탐색이나 교통 상황 변화에 따른 문제는 고려하지 않았음
  - 적응형 ETA(adaptive ETA)를 통해 해결

### 개략적 설계안 - 지도 서비스
- 확대 수준 별 한 벌씩 지도 타일 저장을 위해서는 수백 PB가 필요함
- 확대 수준에 따라 서버에서 필요한 타일을 가져오는 것이 바람직 함
  - 사용자가 지도를 확대 또는 이동시키며 주변 탐색 시
  - 경로 안내 중 사용자 위치가 현재 지도 타일을 벗어나 인접 타일로 이동 시
- 다량의 지도 타일 데이터를 서버에서 효과적으로 가져오기 위한 방법
  - 확대 수준에 근거해 필요한 지도 타일을 즉석에서 만드는 방법
    - 사용자 위치와 확대 수준의 조합이 무한하므로 문제가 생길 수 있음
      - 모든 지도 타일을 동적으로 만들면 서버 클러스터에 부하가 심각함
      - 캐시 활용이 어려움
    - 확대 수준 별 미리 만들어둔 지도 타일을 전달
      - 각 지도 타일은 지오해싱 같은 분할법을 사용해 만들어진 정적인 타일임
      - 지도 타일이 필요하면 현재 확대 수준에 근거해 필요한 지도 타일 집합을 결정하고 각 위치의 지오해시 URL로 변환
      - 미리 만들어둔 정적 이미지는 CDN을 통해 서비스
        - CDN을 통해 접근 시 한 번 접근한 적이 있는 타일은 서버에 다시 요청하지 않아도 됨
        - 또한 POP(Point of Presence)에 캐시되므로 규모 확장에도 용이함
- 모바일 유저에서는 데이터 사용량도 중요하다.
  - 우선 클라이언트 측 캐시는 고려하지 않음
    - 일반적으로 사람들이 많이 사용하는 길은 캐시에 두면 데이터 사용량을 줄일 수 있음
  - 사용자가 30km/h로 이동, 한 이미지가 200m * 200m 크기라고 가정
    - 이미지는 256 * 256 픽셀, 평균 이미지 크기는 100kb
    - 1km * 1km 지역은 25장의 이미지로 표현 가능
    - 이는 2.5MB(25장 * 100kb)의 데이터를 전송해야 함
    - 30km/h 속도로 이동 시 시간당 75MB 데이터가 소진(30km/h * 1시간 * 2.5MB)
    - 분 당 1.25MB에 해당
- CDN을 통해 서비스되는 트래픽 규모
  - 매일 50억 분 가량의 경로 안내를 처리함
  - 50억 분 * 1.25MB = 6.25PB/Day
  - 초 당 62_500MB
  - 이는 전 세계 여러 POP을 통해 제공되므로 각 POP이 감당하는 트래픽은 수백 MB 정도일 수 있음
- 2번째 미리 만들어준 지도 타일을 사용하는 방식에서 CDN에서 가져올 지도 타일 URL을 결정하는 방법
  - 지오해시를 통해 격자를 나누므로 모든 격자는 고유한 지오해시 값을 가짐
  - 위도/경도로 표현된 클라의 위치와 지도 확대 수준과 매칭되는 지도 타일의 지오해시는 쉽게 계산 가능
  - 해당 계산은 클라가 수행하여 해당 지오해시 및 URL로 CDN에서 지도 타일을 가져오면 됨
  - 클라에서 인코딩 프로세스가 있을 경우 인코딩 교체에 문제가 있을 수 있다
    - 특히 모바일 앱의 경우 교체가 어렵고 위험성도 높다
    - 위도/경도, 확대 수준에 따른 URL을 변환해주는 별도의 서비스를 두는 것도 방법이 될 수 있음
- 타일 URL 변환 서비스
  - 모바일 사용자가 타일 URL을 가져오기 위해 지도 타일 서비스를 호출
  - 로드밸런서가 해당 요청을 지도 타일 서비스로 전달
  - 지도 타일 서비스는 클라의 위치와 확대 수준을 입력으로 9개의 타일을 계산해 클라로 반환
    - 표시 할 타일 하나와 주변 8개의 타일임
  - 모바일 클라는 해당 타일을 CDN을 통해 다운로드

## 3단계 - 상세 설계
### 데이터 모델 - 경로 안내 타일
- 도로 데이터는 외부 사업자나 기관이 제공한 것을 이용함
  - 해당 데이터는 수 TB에 달하며 지속적으로 개선됨
  - 방대한 양의 도로와 메타데이터(이름, 관할구, 위도, 경도 등 도로 부속 정보)로 구성
  - 그래프 자료 구조 형태로 가공되지 않은 데이터임
    - 주어진 상태 그대로 경로 안내 알고리즘의 입력으로 사용 불가
    - 경로 안내 타일 처리 서비스(routing tile processing service)라 불리는 오프라인 데이터 가공 파이프라인을 주기적으로 실행해 경로 안내 타일로 변환함
    - 도로 데이터에서 발생한 실시간 변경 사항을 반영하기 위함
  - 각 타일에는 그래프의 노드와 선분으로 표현된 해당 지역 내 교차로와 도로 정보가 포함됨
    - 다른 타일의 도로와 연결되는 경우에는 해당 타일에 대한 참조 정보도 포함됨
    - 경로 안내 알고리즘은 이들 타일이 모인 결과로 만들어지는 도로망 데이터를 점진적으로 소비함
- 가공되어 만들어진 타일 저장
  - 그래프 데이터는 메모리에 인접 리스트(adjacency list)로 저장되는 것이 일반적임
  - 하지만, 본 설계안의 타일 데이터는 메모리에 두기엔 양이 너무 많음
  - 그래프의 노드와 선을 DB 레코드로 처리하는 방법은 비용이 많이 발생함
    - 추가로 경로 안내 타일은 DB가 제공하는 기능이 필요 없음
  - S3 같은 객체 저장소에 파일을 보관하고 그 파일을 이용할 경로 안내 서비스에서 적극적으로 캐싱하는 것이 효율적임
  - 인접 리스트를 이진 파일 형태로 직렬화 해주는 패키지는 많음
  - 타일을 보관 시 지오해시 기준으로 분류해두는 것이 좋음
    - 위도와 경도가 주어지면 빠르게 타일을 찾을 수 있음
  
### 데이터 모델 - 사용자 위치
- 아주 값진 데이터임
- 도로 데이터 및 경로 안내 타일 갱신에 사용됨
- 실시간 교통 상황 데이터나 교통 상황 이력 DB 구축에도 활용 됨
- 데이터 스트림 프로세싱 서비스는 이 위치 데이터를 처리해 지도 데이터를 갱신
- 사용자 위치 데이터를 저장하기 위해선 엄청난 양의 쓰기 연산을 처리하면서 수평 확장이 가능한 DB가 좋음
  - 카산드라 같은 DB가 좋은 후보임

### 데이터 모델 - 지오코딩 데이터
- 주소를 위도/경도 쌍으로 변환하는 정보를 보관
- 레디스처럼 빠른 읽기 연산을 제공하는 key-value 저장소가 적당함
- 읽기는 빈번하지만 쓰기는 드물기 때문임
- 출발지와 목적지 주소는 경로 계획 서비스에 전달 전 이 DB를 통해 위도/경로 쌍으로 변환되어야 함

### 데이터 모델 - 미리 계산해 둔 지도 타일 데이터
- 특정 영역의 지도를 요청하면 인근 도로 정보를 취합해 모든 도로 및 관련 상세 정보가 포함된 이미지를 만들어야 함
- 계산 자원도 많이 사용하고 같은 이미지가 중복 요청되는 경우가 많음
- 이미지는 확대 수준 별로 미리 만들어 CDN을 통해 전송하는 것이 좋음

### 서비스 - 위치 서비스
- 사용자 위치 데이터 저장에는 key-value 저장소를 활용
- 초당 백만 건의 위치 정보 갱신이 발생하기에 쓰기 연산 성능이 중요함
  - NoSQL key-value DB나 열-중심 DB(column-oriented DB)가 적합함
- 사용자 위치는 계속 변경되고 이전 데이터는 필요없어질 수 있음
  - 데이터 일관성보다는 가용성이 더욱 중요함
  - 따라서 가용성과 분할 내성 두 가지 목적에 집중
- DB 키는 (user_id, timestamp)의 조합으로 사용
  - value에는 위도/경도 쌍을 저장
  - user_id는 파티션 키
    - 특정 사용자의 최근 위치를 신속히 읽어 내기 위해
  - timestamp는 클러스터링 키로 활용
  - 같은 파티션 키를 갖는 데이터는 함께 저장되며 클러스터링 키 값에 따라 정렬됨
    - 특정 사용자의 특정 기간 내 위치도 효율적으로 읽을 수 있음

### 사용자 위치 데이터의 이용
- 사용자 위치는 쓰임새가 다양한 중요 데이터임
  - 새 도로 개설이나 폐쇄된 도로 감지 가능
  - 지도 데이터 정확성 개선에 활용 가능
  - 실시간 교통 현황 파악 가능
- 이런 경우를 지원하기 위해 사용자 위치를 DB에 기록하는 것과 별도로 카프카 같은 메시지 큐에 로깅함
- 개별 서비스는 카프카를 통해 전달되는 사용자 위치 데이터 스트림을 용도에 맞게 활용할 수 있음

### 지도 표시 - 지도 타일 사전 계산
- 확대 수준 별 지도 타일을 미리 만듦
- 확대 수준 증가에 따라 타일은 4배 늘어나지만, 각 타일의 크기는 여전히 256 * 256 픽셀임
  - 따라서 확대 수준 증가에 따라 타일 전체를 합친 해상도는 4배씩 증가함

### 최적화 - 벡터 사용
- 지도 표시에 WebGL 기술 채택
  - 네트워크를 통해 이미지를 전송하는 대신 경로(path)와 다각형(polygon) 등의 벡터(vector) 정보를 보냄
  - 클라는 수신된 경로와 다각형 정보를 통해 지도를 그려냄
  - 이미지에 비해 훨등한 압축률을 가짐
    - 네트워크 대역폭이 많이 절약 됨
  - 훨씬 매끄러운 지도 확대가 가능
    - 래스터 방식 이미지(rasterized image) 사용 시 클라가 확대 수준을 높이는 순간 이미지가 늘어지고(stretch) 픽셀이 도드라짐
    - 벡터 방식을 사용하면 클라는 각 요소 크기를 적절하게 조정할 수 있어서 훨씬 매끄러운 확대 경험 제공 가능

### 서비스 - 지오 코딩 서비스
- 주소를 위도와 경도 쌍으로 바꿔주는 서비스가 필요함
- 주소 표현 방식은 다양할 수 있음
  - 장소 이름, 지번 등
- 구글의 사례
```json

```
- 경로 안내 서비스는 이 서비스를 호출해 출발지와 목적지 주소를 위도/경도 쌍으로 변환해 다른 서비스 호출에 이용함
### 서비스 - 경로 계획 서비스
- 경로 계획 서비스(route planner service)는 현재 교통 상황과 도로 상태에 따라 최적화된 경로를 제안
- 다른 서비스들과 통신해 최종 결과를 만들어냄

### 서비스 - 최단 경로 서비스
- 출발지와 목적지 위도/경도를 입력 받아 k개 최단 경로를 반환함
  - 교통이나 도로 상황은 고려하지 않음
  - 도로 구조에만 의존해 계산을 수행
  - 도로망 그래프는 거의 정적이므로 캐시해두면 좋음
- 객체 저장소로 저장된 안내 타일에 대해 A* 경로 탐색 알고리즘의 한 형태를 실행함
  - 입력으로 출발지와 목적지의 위도/경도를 받음
    - 이 위치 정보를 지오해시로 변환해 출발지와 목적지 경로 안내 타일을 얻음
  - 출발지 타일에서 시작해 그래프 자료 구조를 탐색해 나감
    - 탐색 범위를 넓히는 과정에서 필요한 주변 타일은 객체 저장소에서 가져옴
    - 같은 지역의 다른 확대 수준 타일로도 연결될 수 있음.
    - 최단 경로가 충분히 확보될 때까지 검색 범위를 확대해 나가면서 필요한 만큼 타일을 가져오는 작업을 반복함

### 서비스 - 예상 도착 시간 서비스
- 최단 경로 목록을 수신하면 예상 도착 시간 서비스(ETA service)가 각 경로에 대한 예상 도착 시간을 계산함
- 예상 도착 시간은 기계 학습을 활용해 현재 교통 상황 및 과거 이력에 근거해 예상 도착 시간을 계산함
- 까다로운 점은 현재 교통 데이터만이 아니라 10분, 20분 뒤 미래의 교통 상황도 예측해야한다는 것임
  - 이는 또 다른 내용의 문제이므로 이번에는 패스

### 서비스 - 순위 결정 서비스
- ETA 예상치를 구한 후 순위 결정 서비스에 관련 정보를 모두 전달해 사용자가 정의한 필터링 조건을 적용함
- 유료 도로 제외, 고속도로 제외 등
- 필터링 후 남은 경로를 소요 시간 순 등으로 정렬해 최단 시간 경로 k개를 구해 경로 안내 서비스에 반환

### 서비스 - 중요 정보 갱신 서비스들
- kafka 위치 데이터 스트림을 구독하고 있다가 중요 데이터를 비동기적으로 갱신해 최신 상태를 유지하는 역할을 담당
  - 실시간 교통 정보 DB나 경로 안내 타일 등
  - 새로 발견된 도로나 폐쇄된 도로 등을 반영해 경로 안내 타일을 지속적으로 갱신함
- 실시간 교통 상황 서비스는 사용자가 보내는 위치 데이터 스트림을 통해 교통 상황 정보를 추출
  - 더욱 정확한 예상 도착 시간 서비스를 제공

### 적응형 ETA와 경로 변경
- 현재는 적응형 ETA와 경로 변경을 허용하지 않음
- 이를 해결하기 위해서는 경로 안내를 받는 모든 사용자를 추적해 교통 상황이 달라질 때마다 각 사용자의 ETA를 변경해 주어야 함
  - 현재 경로 안내를 받는 사용자를 어떻게 추적하는가?
  - 수백만 경로 가운데 교통 변화의 영향을 받는 경로와 사용자를 효율적으로 어떻게 가려내는가?
- 사용자가 안내 받는 모든 경로 타일을 저장하고, 영향을 받는 모든 타일을 검색
  - 보관된 레코드 수가 n이고, 경로 평균 길이가 m이라면 모든 사용자 검색에 드는 시간 복잡도는 O(n * m)임
- 경로 안내를 받는 사용자의 현재 경로 안내 타일과 그 타일을 포함하는 상위 수준의 타일, 그 상위 타일의 상위 타일을 출발지와 목적지가 모두 포함된ㄴ 타일을 찾을 때까지 재귀적으로 더해 보관
  - ETA가 달라지는 사용자는 DB 레코드 마지막 타일에 그 타일에 속하는 사용자
  - 시간 복잡도는 O(n)임
- 교통 상황이 개선되었을 때 일을 해결하진 않음
  - 주기적으로 재계산해 사용자에게 더 짧은 ETA가 발견되면 알리는 방법을 사용할 수 있음

### 전송 프로토콜
- 경로 안내 중 경로 상황이 바뀔 수 있음
  - 데이터를 모바일 클라이언트에게 전송할 안정적인 방법이 필요함
  - 모바일 푸시 알림(mobile push notification), 롱 폴링(long polling), 웹소켓(websocket), 서버 전송 이벤트(SSE, server-sent event) 등이 있음
  - 모바일 푸시 알림은 보낼 수 있는 메시지 크기가 매우 제한적이므로 조심해야함(iOS의 경우 최대 4_096바이트)
    - 웹 애플리케이션은 지원하지 않음
  - 웹소켓은 서버에 주는 부담이 크지 않아서 일반적으로 롱 폴링보다 좋은 방안으로 봄
  
## 4단계 - 마무리
- 추가적인 논의 사항
  - 중간 경유지 설정 기능
  - 여러 목적지 입력 시 추천 경로 순서
  - 

---
# 4장 - 분산 메시지 큐
- 현대 시스템은 잘 정의된 인터페이스를 경계로 나뉜 작고 독립적인 블록들로 구성됨
- 메시지 큐는 이 블록 사이의 통신과 조율을 담당함
- 결합도 완화
  - 컴포넌트 사이의 강한 결합이 사라져 각각을 독립적으로 갱신 가능
- 규모 확장성 개선
  - 데이터를 생산하는 생상자와 메시지를 소비하는 소비자 시스템 규모를 트래픽 부하에 맞게 독립적으로 확장 가능
- 가용성 개선
  - 특정 컴포넌트에 장애가 발생해도 다른 컴포넌트는 큐와 계속 상호작용 가능
- 성능 개선
  - 비동기 통신에 용이함
  - 생산자는 응답을 기다리지 않고도 메시지를 보낼 수 있음
  - 소비자는 읽을 메시지가 있을 때만 해당 메시지를 소비 가능
  - 서로 기다리지 않아도 됨

### 메시지 큐 vs 이벤트 스트리밍 플랫폼
- kafka나 펄사(pulsar)는 엄밀히는 이벤트 스트리밍 플랫폼(event streaming platform)임
- RabbitMQ, ActiveMQ 같은 메시지 큐와 점차 구분이 희미해지고 있음
  - 스트리밍 기능 추가 시 메시지를 반복적으로 소비와 데이터 장기 보관도 가능
  - 해당 기능은 데이터 추가만 가능한 로그를 통해 구현
    - 이는 이벤트 스트리밍 플랫폼 구현과 유사함
- 데이터 장기 보관(long data retention), 메시지 반복 소비(re-peated consumption of messages)등의 부가 기능을 갖춘 분산 메시지 큐를 설계함

## 1단계 - 문제 이해 및 설계 범위 확정
- 메시지 큐의 기본 기능
  - 생산자는 메시지를 큐에 보냄
  - 소비자는 큐에서 메시지를 꺼내어 소비함
- 추가적인 고려 사항
  - 성능
  - 메시지 전달 방식
  - 데이터 보관 기관 등
- Q) 메시지의 형태와 평균 크기는? 텍스트만 지원하는지, 멀티 미디어 등도 지원하는지?
  - A) 텍스트 형태만 지원. 평균 크기는 수 KB 수준
- Q) 반복적으로 소비될 수 있어야 하는가?
  - A) 네. 하나의 메시지를 여러 소비자가 수신할 수 있어야함. 부가 기능임. 전통적인 분산 메시지 큐는 한 소비자라도 소비하면 지워짐.
- Q) 큐에 전달된 순서대로 소비되어야 하는가?
  - A) 네. 부가 기능일 뿐임. 전통적인 분산 메시지 큐는 보통 소비 순서를 보증하지 않음.
- Q) 데이터 지속성이 보장 되어야 하는지, 기간은 얼마나 되어야 하는지?
  - A) 네 2주라고 가정. 이것도 부가기능임. 전통적인 분산 메시지 큐는 보장하지 않음
- Q) 지원해야하는 생산자와 소비자 수는?
  - A) 많으면 좋음
- Q) 어떤 메시지 전달 방식을 지원해야 하는가? 최대 한 번(at-most-once), 최소 한 번(at-least-once), 정확히 한 번(exactly-once)
  - A) '최소 한 번'은 무조건 지원하고 모두 다 지원하면 좋으며 사용자가 지정할 수 있으면 좋음
- Q) 목표 대역폭(throughput)과 단대단(end-to-end) 지연 시간은?
  - A) 로그 수집 등에서도 쓰기 위해 높은 수준의 대역폭을 제공해야 함. 낮은 전송 지연도 필수

### 기능 요구 사항
- 생산자는 메시지 큐에 메시지를 보낼 수 있어야 함
- 소비자는 메시지 큐를 통해 메시지를 수신할 수 있어야 함
- 메시지는 반복적으로 수신할 수 있어야 하고, 단 한번만 수신하게 설정할 수도 있어야 함
- 오래된 이력 데이터는 삭제될 수 있음
- 메시지 크기는 킬로바이트 수준
- 메시지가 생산된 순서대로 소비자에게 전달할 수 있어야 함
- 메시지 전달 방식은 최소 한 번, 최대 한 번, 정확히 한 번 중 설정할 수 있어야 함

### 비기능 요구 사항
- 높은 대역폭과 낮은 전송 지연 가운데 하나를 설정으로 선택 가능한 기능
- 규모 확장성. 분산 시스템일 가능성이 높으므로 메시지 양이 급증해도 처리 가능해야 함
- 지속성 및 내구성(persistency and durability)

### 전통적 메시지 큐와 다른 점
- RabbitMQ 같은 전통 메시지 큐는 이벤트 스트리밍 플랫폼처럼 메시지 보관 문제를 중요하게 다루지 않음
- 메시지가 소비자에게 전달될 충분한 시간 동안만 메모리에 보관함
- 처리 용량을 넘어도 보관하긴 하지만 이벤트 스트리밍 플랫폼이 감당하는 것보다 아주 낮음
- 메시지 전달 순서도 보존하지 않음
  - 생산 순서와 소비 순사가 다를 수 있음

## 2단계 - 개략적 설계안 제시 및 동의 구하기
- 메시지 큐의 기능
  - 생산자는 메시지를 메시지 큐에 발행
  - 소비자는 큐를 구독(subscribe)해 메시지를 소비
  - 메시지 큐는 생산자-소비자 사이의 결합도를 낮춤.
    - 독립적인 운영과 규모 확장이 가능하게 해줌

### 메시지 모델 - 일대일 모델
- 전통적인 메시지 큐에서 흔히 쓰이는 모델
- 일대일 모델에서 큐에 전송된 메시지는 한 소비자만 소비 가능함
- 어떤 소비자가 메시지를 가져갔다는 사실을 큐에 알리면 해당 메시지는 큐에서 삭제됨
- 데이터 보관을 지원하지 않음
- 지속성 계층(persistence layer)를 포함해 이를 통해 메시지가 반복 소비되게 할 수 있음

### 메시지 모델 - 발행-구독 모델
- 토픽이라는 새로운 개념을 도입
  - 메시지를 주제별로 정리하는 데 사용됨
  - 각 토픽은 메시지 큐 서비스 전반에 고유한 이름을 가짐
  - 메시지를 보내고 받을 때 토픽에 보내고 받음
  - 토픽에 전달된 메시지는 해당 토픽을 구독하는 모든 소비자에게 전달 됨

### 토픽, 파티션, 브로커
- 토픽에 보관되는 데이터가 커져서 서버 한 대로 감당하지 못할 때
  - 파티션을 활용함(샤딩 기법)
  - 토픽을 여러 파티션으로 분할
    - 파티션은 토픽에 보낼 메시지의 작은 부분집합
    - 파티션은 메시지 큐 클러스터 내의 서버에 고르게 분산 배치함
  - 파티션을 유지하는 서버를 브로커(broker)라고 부름
    - 파티션을 브로커에게 분산해서 높은 규모 확장성을 달성 가능
    - 파티션 개수 증가 -> 토픽 용량 확장
  - 각 토픽 파티션은 FIFO 큐처럼 동작함
    - 같은 파티션 내부에서 메시지 순서가 유지 됨
    - 파티션 내에서 메시지 위치는 오프셋(offset)라고 함
  - 메시지에는 사용자 ID 같은 키를 붙일 수 있는데, 같은 키를 가진 모든 메시지는 같은 파티션으로 전달됨
    - 키가 없는 메시지는 무작위 파티션으로 전송
  - 토픽의 구독자가 여럿일 경우 각 구독자는 해당 토픽을 구성하는 파티션의 일부를 담당함
    - 이 소비자를 해당 토픽의 소비자 그룹(consumer group)이라고 부름

### 소비자 그룹
- 소비자 그룹 내 소비자는 토픽에서 메시지를 소비하기 위해 서로 협력함
- 하나의 소비자 그룹은 여러 토픽을 구독할 수 있고 오프셋을 별도로 관리함
- 데이터를 병렬로 읽으면 대역폭 측면에서는 좋지만, 같은 파티션 안에 있는 메시지를 순서대로 소비할 수 없음
  - 파티션의 메시지를 한 그룹 안에서 한 소비자만 읽을 수 있게하면 해결 가능
  - 그룹 내의 소비자 수가 구독하는 토픽의 파티션 수보다 크면 어떤 소비자는 데이터를 못 읽음
  - 이 경우 모든 소비자를 한 그룹에 두면 일대일 모델처럼 돼버림
- 파티션은 가장 작은 저장 단위이므로 미리 충분한 파티션을 할당해야 함
  - 처리 용량을 늘리려면 소비자를 더 추가

### 개략적 설계안
- 클라이언트
  - 생산자
    - 메시지를 특정 토픽으로 보냄
  - 소비자 그룹
    - 토픽을 구독하고 메시지를 소비
- 핵심 서비스 및 저장소
  - 브로커
    - 파티션들을 유지함.
    - 하나의 파티션은 특정 토픽에 대한 메시지의 부분 집합을 유지
  - 저장소
    - 데이터 저장소
      - 메시지는 파티션 내 데이터 저장소에 보관
    - 상태 저장소
      - 소비자 상태는 이 저장소에 유지
    - 메타데이터 저장소
      - 토픽 설정, 토픽 속성(property) 등은 이 저장소에 유지
- 조정 서비스(coordination service)
  - 서비스 탐색(service discovery)
    - 어떤 브로커가 살아있는지 알려줌
  - 리더 선출(leader election)
    - 브로커 가운데 하나는 컨트롤러 역할을 해야함
    - 한 클러스터에서 반드시 활성 상태 컨트롤러가 하나 있어야 함
    - 이 컨트롤러가 파티션 배치를 책임짐
  - 아파치 주키퍼(apache zookeeper)나 엣시디(etcd) 같은 서비스가 보통 컨트롤러 선출을 담당하는 컴포넌트로 사용됨

## 3단계 - 상세 설계
- 디스크 기반 자료 구조(on-disk data structure)를 활용
  - 회전 디스크(rotational disl)의 높은 순차 탐색 성능, 현대 OS가 제공하는 적극적 디스크 캐시 전략(aggrerssive disk caching strategy)를 잘 이용함
- 메시지가 생산자에서 소비자에게 전달되는 순간까지 아무 수정 없어도 전송 가능하게 메시지 자료 구조를 설계하고 활용
  - 전송 데이터 양이 막대한 경우 메시지 복사에 드는 비용을 최소화하기 위함
- 일괄 처리(batching)을 우선하는 시스템을 설계
  - 소규모 I/O가 많으면 높은 대역폭 지원이 어려움.
  - 생산자는 메시지를 일괄 전송
  - 메시지 큐는 그 메시지들을 더 큰 단위로 묶어서 보관
  - 소비자도 가능하면 메시지 일괄 수신

### 데이터 저장소
- 메시지 큐의 트래픽 패턴
  - 읽기와 쓰기가 빈번함
  - 갱신/삭제 연산은 없음
    - 전통적인 메시지 큐는 메시지가 신속하게 전달되지 못해 큐가 제때 비워지지 않는 경우를 제외하곤 메시지를 지속적으로 보관하지 않음
    - 큐에서 메시지를 제때 소비하기 시작하면 저장된 메시지에 대한 삭제 연산이 발생하긴 함
    - 지금 말하는 데이터 지속성은 데이터 스트리밍 플랫폼에 관계된 것
  - 순차적 읽기/쓰기가 대부분임

### 데이터 저장소 - 선택지 1 : DB
- RDB
  - 토픽별로 테이블을 만듦
    - 토픽에 보내는 메시지는 해당 테이블에 새로운 레코드로 추가
- NoSQL
  - 토픽별로 컬렉션(collection)을 만듦
    - 토픽에 보내는 메시지는 하나의 문서가 됨
- DB는 데이터 저장 요구사항은 맞출 수 있음
- 대규모 읽기/쓰기 처리가 쉽지 않음

### 데이터 저장소 - 선택지 2 : 쓰기 우선 로그(Write-Ahead Log, WAL)
- WAL은 새로운 항목이 추가되기만 하는 일반 파일(append-only)
- MySQL 복구 로그(redo log), 아파치 주키퍼 등에서 활용
- WAL에 대한 접근 패턴은 읽기/쓰기 전부 순차적임
  - 디스크에 WAL로 보관하면 좋음
    - 접근 패턴이 순차적일 때 디스크는 아주 좋은 성능을 보임
    - 회전식 디스크 기반 저장장치는 큰 용량에 저렴한 가격으로 제공함
    - 새로운 메시지는 파티션 꼬리 부분에 추가되며, 오프셋은 그 결과로 점진적으로 증가함
    - 가장 쉬운 방법은 로그 파일 줄 번호를 오프셋으로 사용하는 것.
      - 파일 크기도 무한정 커질 수 없으니 세그먼트 단위로 나누느 것이 바람직 함
      - 세그먼트 사용 시 새 메시지는 활성 상태의 세그먼트 파일에만 추가됨
      - 세그먼트의 크기가 일정 한계에 도달하면 새 활성 세그먼트 파일이 만들어져 새로운 메시지를 수용하고, 비활성 상태로 변경됨
      - 비활성 세그먼트는 읽기 요청만 처리함.
      - 낡은 비활성 세그먼트는 보관 기한 만료나 용량 한계 시 삭제 가능

### 디스크 성능 관련 유의사항
- 회전식 디스크는 데이터 접근 패턴이 무작위일 때 아주 느려짐
- 순차적 데이터 접근 패턴을 적극 활용하면 RAID로 구성된 현대적 디스크 드라이브에서 수백 MB/s 읽기/쓰기는 크게 어렵지 않음
- 이 정도면 요구 사항을 충족할 수 있고 비용도 만족스럽다
- OS에서는 디스크 데이터를 메모리에 아주 적극저긍로 캐시함
- WAL도 OS가 제공하는 디스크 캐시 기능을 적극적으로 활용함

### 메시지 자료 구조
- 메시지 구조는 높은 대역폭 달성의 열쇠임
- 생산자, 메시지 큐, 그리고 소비사 사이의 계약(contract)가 여기 해당함
- 메시지가 소비자에게 전달되는 과정에서 불필요한 복사가 일어나지 않게 해 높은 대역폭을 달성함
- 시스템 컴포넌트 중 이 계약을 그대로 받아들이지 못함녀 메시지가 변경되고, 값비싼 복사(copy)가 발생함

### 메시지 자료 구조 - 메시지 키
- 메시지의 키는 파티션을 정할 때 사용됨
- 키가 주어지지 않은 메시지는 무작위로 파티션이 결정 됨
- 키가 주어지면 hash(key) % 파티션 수로 파티션을 결정함
  - 파티션 선정 메커니즘을 생산자가 직접 정의할 수도 있음.
  - 키는 파티션 번호가 아님 주의
- 키에는 비즈니스 관련 정보가 담기는 것이 보통임
- 파티션 번호는 큐 내부적으로 사용되는 개념이므로 클라이언트에게 노출되어서는 안됨
- 키-파티션 대응 알고리즘을 적절히 저으이하면 파티션 수가 달라져도 모든 파티션에 메시지가 계속 균등히 분산되게 할 수 있음

### 메시지 자료 구조 - 메시지 값
- 메시지의 내용, 페이로드(payload)를 말함
- 텍스트일 수도 있고, 압축된 이진 블록(block)일 수도 있음
- 메시지의 키와 값은 key-value 에서 얘기하는 키, 값과는 다름
  - 메시지의 키는 메시지마다 교유할 필요가 없으며, 키가 반드시 필요한 것도 아님.
  - 키를 사용해 값을 찾을 필요도 없음
- 기타 필드
  - 토픽(topic)
    - 메시지가 속한 토픽의 이름
  - 파티션(partition)
    - 메시지가 속한 파티션 ID
  - 오프셋(offset)
    - 메시지가 속한 파티션 내에서의 위치
    - 메시지는 토픽, 파티션, 오프셋 세 가지 정보로 찾을 수 있음
  - 타임스탬프(timestamp)
    - 메시지가 생성된 시간
  - 크기(size)
    - 메시지 크기
  - CRC(순환 중복 검사, Cyclic Redundancy Check)
    - 메시지의 무결성을 보장하는데 사용됨

### 일괄 처리
- 생산자, 소비자, 메시지 큐는 메시지를 가급적 일괄 처리함
- 일괄 처리로 인한 성능 개선
  - 한 번의 네트워크 요청으로 여러 메시지를 처리하면 값비싼 네트워크 왕복 비용을 줄일 수 있음
  - 브로커가 여러 메시지를 한 번에 로그에 기록 시 더 큰 규모의 순차 쓰기 연산이 발생
    - OS가 관리하는 디스크 캐시엑서 더 큰 규모의 연속된 공간을 차지
    - 더 높은 디스크 접근 대역폭 달성 가능
- 높은 대역폭과 낮은 응답 지연은 동시 달성이 어려움
  - 전통 메시지 큐 이용 시 낮은 응답 지연을 얻을 수 있음.(일괄 처리 메시지 양은 낮아짐)
  - 디스크 성능이 다소 낮아짐
  - 처리량을 높이고 싶을 경우 토픽당 파티션의 수를 늘림
  - 낮아진 순차 쓰기 연산 대역폭을 벌충할 수 있음

### 생산자 측 작업 흐름
- 생산자가 어떤 파티션에 메시지를 보낼 때 어떤 브로커에 연결해야 하는가?
  - 라우팅 계층을 도입하는 방법
    - 라우팅 계층이 적절한 브로커에게 메시지를 보내는 역할을 담당
    - 브로커를 여러 개 운용하는 경우 적절한 브로커는 보통 리더 브로커임
    - 생산자가 파티션으로 메시지를 보내는 과정
      - 생산자가 메시지를 라우팅 계층으로 보냄
      - 라우팅 계층은 메타데이터 저장소에서 사본 분산 계획(replica distribution plan)을 읽어 자기 캐시에 보관
        - 메시지가 도착하면 라우팅 계층은 파티션에 리더 사본을 보냄.
      - 리더 사본이 우선 메시지를 받고, 리더는 다른 사본 브로커들에게 전달함
      - 충분한 수의 사본이 동기화되면 리더는 데이터를 디스크에 기록함
        - 데이터 소비 가능 상태가 되는 것이 이 시점.
        - 기록이 끝나면 생산자에게 회신을 보냄
- 리더와 사본이 필요한 이유
  - 장애 감내(fault tolerance)가 가능한 시스템을 만들기 위함
  - 위에서 생산자가 파티션으로 메시지를 보내는 과정의 문제점
    - 라우팅 계층을 도입하면 중간에 거칠 네트워크 노드가 하나 늘어나므로 오버헤드가 발생하고 네트워크 전송 지연이 늘어남
    - 일괄 처리가 힘들어짐
- 라우팅 계층을 생산자 내부로 편입시키고 버퍼를 도입
  - 생산자 클라이언트 라이브러리(producer client library)의 일부로 생산자에 설치
  - 네트워크로 인한 전송 지연이 줄어듦
  - 생산자는 메시지를 어느 파티션으로 보낼지 자신만의 로직을 가질 수 있음
  - 전송할 메시지를 버퍼 메모리에 보관했다가 목적지로 일괄 전송해 대역폭을 높일 수 있음
- 일괄 처리 시 메시지 양을 늘리면 대역폭이 늘어나지만 응답속도가 느려짐
  - 메시지가 일괄 처리 가능한 양이 되게 기다려야하기 때문임.
  - 적당한 타협점을 잘 찾아야함

### 소비자 측 작업 흐름
- 소비자는 특정 파티션의 오프셋을 주고 해당 위치에서 이벤트를 묶어서 가져옴

### 푸시 vs 풀 - 푸시 모델
- 장점
  - 낮은 지연
    - 브로커는 메시지를 받는 즉시 소비자에게 보낼 수 있음
- 단점
  - 소비자의 메시지 처리 속도보다 생산자의 생산 속도가 빠르면 소비자에게 부하가 걸림
  - 생산자가 데이터 전송 속도를 좌우해 소비자는 그에 맞는 컴퓨팅 자원을 준비해야함

### 푸시 vs 풀 - 풀 모델
- 장점
  - 메시지 소비 속도를 소비자가 결정함
    - 소비자에 따라 실시간으로 가져가거나 배치로 가져가는 등을 구성할 수 있음
  - 메시지 소비 속도가 생산 속도보다 느려지면 소비자를 늘리거나 생산 속도를 따라잡을 때까지 기다려도 됨
  - 일괄 처리에 적합함
    - 푸시 모델에서 브로커는 소비자가 메시지를 처리할 수 있는 상태인지 모름
      - 소비자가 제때 처리하지 못 할 경우 메시지는 버퍼에 쌓여서 처리를 기다림
    - 풀 모델은 소비자가 마지막으로 가져간 로그 위치 다음에 오는 모든 메시지를(혹은 설정된 최대 개수 만큼) 한 번에 가져갈 수 있음.
      - 데이터의 공격적인 일괄 처리에 좀 더 적합함
- 단점
  - 브로커에 메시지가 없어도 소비자가 계속 데이터를 가져가려하기에 소비자 측 컴퓨팅 자원이 낭비됨
  - 이 문제를 극복하기 위해 많은 메시지 큐가 롱 폴링 모드를 지원함.
    - 당장 메시지가 없어도 일정 시간을 기다리게 함
- 동작 방식
  - 소비자는 그룹 이름을 해싱해 접속할 브로커 노드를 찾음
    - 같은 그룹의 모든 소비자는 같은 브로커에 접속함
    - 이 브로커를 해당 소비자 그룹의 코디네이터라 부름
    - 코디네이터는 조정 서비스와 다름.
      - 코디네이터는 소비자 그룹의 조정 작업만 담당
      - 조정 서비스는 브로커 클러스터 조정 작업을 담당
  - 코디네이터는 해당 소비자를 그룹에 참여시키고 파티션을 소비자에게 할당
  - 소비자는 마지막으로 소비한 오프셋 이후 메시지를 가져옴
    - 오프셋 정보는 상태 저장소에 있음
  - 소비자는 메시지를 처리하고 새로운 오프셋을 브로커에게 보냄.
    - 데이터 처리와 오프셋 갱신 순서는 메시지 전송 시맨틱에 영향을 미침

### 소비자 재조정
- 어떤 소비자가 어떤 파티션을 책임지는지 다시 정하는 프로세스
  - 새로운 소비자 합류, 기존 소비자가 그룹을 떠나거나, 소비자에 장애 발생, 파티션 조정 등에 의해 시작됨
- 코디네이터가 중요한 역할을 함
  - 코디네이터는 소비자 재조정을 위해 소비자들과 통신하는 브로커 노드임
  - 소비자로부터 오는 박동 메시지를 살피고 각 소비자의 파티션 내 오프셋 정보를 관리함
- 코디네이터와 소비자의 상호 작용
  - 각 소비자는 특정 그룹에 속함
    - 그룹 전담 코디네이터는 그룹 이름을 해싱해 찾을 수 있음
    - 같은 그룹의 모든 소비자는 같은 코디네이터에 연결됨
  - 코디네이터는 자신에 연결한 소비자 목록을 유지함
    - 이 목록에 변화가 생기면 코디네이터는 해당 그룹의 새 리더를 선출함
  - 새 리더는 새 파티션 배치 계획(partition dispatch plan)을 만들고 코디네이터에게 전달
    - 코디네이터는 해당 계획을 그룹 내 다른 모든 소비자에게 알림

### 상태 저장소
- 소비자에 대한 파티션의 배치 관계
- 각 소비자 그룹이 각 파티션에서 마지막으로 가져간 메시지의 오프셋
  - 특정 소비자에게 장애가 생겨 새로운 소비자가 그룹을 이어 받아갈 때 해당 위치부터 메시지를 읽어갈 수 있음
- 소비자 상태 정보 데이터가 이용되는 패턴
  - 읽기/쓰기가 빈번하지만 양은 많지 않음
  - 데이터 갱신은 빈번하지만 삭제는 거의 없음
  - 읽기와 쓰기 연산은 무작위적 패턴을 보임
  - 데이터의 일관성(consistency)가 중요함
  - 주키퍼 같은 key-value를 사용하는 것이 좋음

### 메타데이터 저장소
- 토픽 설정이나 속성 정보를 보관
  - 파티션 수, 메시지 보관 기간, 사본 배치 정보 등
- 자주 변경되지 않고 양도 적음. 대신 높은 일관성을 요구함.
  - 이런 데이터 보관에 주키퍼가 적절함

### 주키퍼
- 계층적 key-value 저장소(hierarchical key-value store) 기능을 제공
- 분산 설정 서비스(disributed configuration service), 동기화 서비스(synchronization service), 이름 레지스트리(naming registry) 등으로 사용됨
- 메타데이터와 상태 저장소를 주키퍼를 이용해 구현
- 브로커는 메시지 데이터 저장소만 유지하면 됨
- 주킼퍼가 브로커 클러스터의 리더 선출 과정을 도움

### 복제
- 하드웨어 장애는 흔한 일임.
- 높은 가용성 보장을 위해 전통적으로 많이 사용되는 방법이 복제임
- 각 파티션은 사본을 갖고 해당 사본은 서로 다른 브로커 노드에 분산됨
- 생산자는 파티션에 메시지를 보낼 때 리더에게만 보냄
  - 사본들은 리더에게 새 메시지를 지속적으로 가져와 동기화함
  - 메시지를 완전히 동기화 한 사본의 개수가 지정된 수에 도달하면 메시지를 잘 받았다는 응답(aclnowledgement)을 리더에게 보냄
- 사본 분산 계획(replica distribution plan)은 리더 브러커 노드가 만들고 메타데이터 저장소에 보관함

### 사본 동기화
- 동기화된 사본(In-Sync Replica, ISR)은 리더와 동기화된 사본을 말함
  - 동기화의 의미는 토픽의 설정에 따라 다름
  - replica.lag.max.message 값이 4일 경우 단순 사본에 보관된 메시지 개수와 리더 사읭 차이가 3이라면 해당 사본은 ISR임
  - ISR은 성능과 영속성 사이의 타협점임

### ACK
- ACK = all
  - 모든 ISR이 메시지를 수신한 뒤 ACK 응답을 받음.
  - 가장 느린 ISR의 응답을 기다려야해 메시지를 보내기 위한 시간이 길어짐
  - 메시지의 영속성 측면에서 가장 좋은 구성임
- ACK = 1
  - 리더가 메시지를 저장하고 나면 바로 ACK 응답을 받음.
  - 응답 지연이 개선됨
  - 리더에 장애가 생기면 메시지가 손실될 수 있음
- ACK = 0
  - 수신 확인 메시지를 기다리지않고, 어떤 재시도도 하지 않음
  - 지표 수집이나 데이터 로깅 등 처리해야 할 메시지 양이 많고 데이터 손실이 상관 없는 경우 사용

### ISR 조건을 만족하는 사본에서 메시지를 가져가지 않는 이유
- 설계 및 운영이 단순하기 때문
- 특정 파티션의 메시지는 같은 소비자 그룹 안에서 오직 한 소비자만 읽어갈 수 있으므로 사본에 대한 연결은 많지 않음
- 아주 인기 있는 토픽이 아니면 사본에 대한 연결의 수는 그렇게 많지 않음
- 아주 인기 있는 토픽은 파티션 및 소비자 수를 늘려 규모를 확장하면 됨

### 규모 확장성
- 생산자
  - 소비자에 비해 개념저긍로 훨씬 간단함
  - 그룹 단위 조정에 가담할 필요가 없음.
  - 새로운 생산자를 추가하거나 삭제해 쉽게 달성 가능
- 소비자
  - 소비자 그룹은 서로 독립적이므로 새 소비자 그룹은 쉽게 추가/삭제 가능
  - 같은 그룹 내에서 소비자 추가/제거, 장애 복구의 경우 재조정(rebalancing) 매커니즘이 처리함
  - 소비자 측의 규모 확장성과 결함 내성(fault tolerance)를 보장하는 것은 소비자 그룹과 재조정 메커니즘임
- 브로커
  - 브로커의 결함 내성을 높이기 위해 추가적으로 고려해야 할 사항
    - 메시지가 성공적으로 합의(committed)되었다고 판단하려면 얼마나 많은 사본에 메시지가 반영되어야 하는지?
    - 사본은 서로 다른 노드에 두어야함
    - 사본은 여러 데이터 센터에 분산하는 것이 안전함.
      - 데이터 동기화로 인한 응답 지연과 비용이 늘어남
      - 데이터 미러링을 통해 데이터 센터 간 데이터 복사를 용이하게 하는 것도 방법 중 하나임
  - 가장 간단한 방법은 브로커 노드가 추가되거나 삭제될 때 사본을 재배치하는 것임
- 파티션
- 

## 4단계 - 마무리

