# 9장 - S3와 유사한 객체 저장소
- S3는 AWS가 제공하는 RESTful API 기반 인터페이스로 사용하는 객체 저장소 서비스임
- 버전 관리, 버킷 정책, 멀티파트 업로드, 서버 측 암호화, 여러 객체 삭제, 객체 만료 등을 지원
- 수명 주기 정책, 이벤트 알림, 지역 간 복제 등의 기능 도입
- 2021년 아마존은 S3에 저장된 객체가 100조 개가 넘는다고 함

## 저장소 시스템 101
- 저장소 시스템의 3가지 부류
  - 블록 저장소
  - 파일 저장소
  - 객체 저장소

### 블록 저장소
- 1960년대 처음 등장
- HDD, SSD처럼 서버에 물리적으로 연결되는 형태의 드라이브가 가장 흔한 형태임
- 서버는 원시 블록을 포맷한 다음 파일 시스템을 이용하거나 가상 머신 엔진 같은 애플리케이션에 블록 제어권을 넘겨버릴 수도 있음
- DB나 가상 머신 엔진 같은 애플리케이션은 원시 블록을 직접 제어해 최대한의 성능을 끌어 냄
- 물리적으로 직접 연결되는 저장소에 국한되지 않음
- 고속 네트워크나 FC(Fibre Channel)이나 iSCSI를 통해 연결될 수도 있음
- 네트워크를 통해 연결되는 블록 저장소도 원시 블록을 제공한다는 점에서 다르지 않음
  - 서버 입장에서는 물리적으로 연결된 블록 저장소와 동일하게 동작 함

### 파일 저장소
- 파일 저장소는 블록 저장소 위에 구현됨
- 파일과 디렉토리를 다루기 쉽게하는 더 높은 수준의 추상화를 제공함
- 데이터는 계층적으로 구성되는 디렉토리 안에 보관됨
- 파일 저장소는 가장 널리 사용되는 범용 저장소 솔루션임
- SMB/CIFS나 NFS 같은 파일 수준 네트워크 프로토콜 사용 시 하나의 저장소에 여러 서버를 동시에 붙일 수도 있음
- 서버는 블록을 직접 제어하고, 포맷하는 등의 작업을 신경 쓸 필요가 없음

### 객체 저장소
- 새로운 형태의 저장소임
- 데이터 영속성을 높이고 대규모 애플리케이션을 지원하고 비용을 낮추기 위해 의도적으로 성능을 희생함
- 실시간 갱신이 필요가 없는 상대적으로 '차가운(cold)' 데이터 보관에 초점을 맞춰 아카이브나 백업에 주로 쓰임
- 모든 데이터를 수평적 구조 내에 객체로 보관함
- 계층적 디렉토리 구조는 제공하지 않음
- RESTful API를 통해 객체를 저장하고 검색함
- 다른 유형의 저장소에 비해 상대적으로 느림

|--| 블록 저장소 | 파일 저장소 | 객체 저장소 |
|--|--|--|--|
|저장된 내용의 변경 가능성 | Y | Y | N(직접 변경은 불가, 객체 버전을 통해 새로운 버전의 객체 추가는 가능) |
| 비용 | 고 | 중 ~ 고 | 저 |
| 성능 | 중 ~ 고 혹은 최상 | 중 ~ 고 | 저 ~ 중 |
| 데이터 일관성 | 강력 | 강력 | 강력 |
| 데이터 접근 | SAS/iSCSI/FC | 표준 파일 적븐, CIFS/SMB, NFS | RESTful API |
| 규모 확장성 | 중 | 고 | 최상 |
| 적합한 응용 | VM, DB같은 높은 성능이 필요한 애플리케이션 | 범용적 파일 시스템 접근 | 이진 데이터, 구조화되지 않은 데이터 |

### 용어 정리
- S3 설계를 위해서는 핵심 개념이해가 필요함
- 버킷
  - 객체를 보관하는 논리적 컨테이너
  - 버킷 이름은 전역적으로 유일해야 함
  - S3에 데이터 업로드를 위해서는 버킷부터 만들어야 함
- 객체
  - 객체는 버킷에 저장하는 개별 데이터를 의미
    - 데이터(페이로드라고도 함)와 메타데이터를 가짐
    - 데이터는 어떤 것도 가능
  - 메타 데이터는 객체를 기술하는 이름-값 쌍의 집합
- 버전
  - 한 객체의 여러 버전을 같은 버킷에 저장하게 하는 기능
  - 버킷마다 별도 설정 가능
  - 실수로 지우거나 덮어쓴 객체를 복구할 수 있게 함
- URI(Uniform Resource Identifier)
  - 객체 저장소는 버킷과 객체에 접근할 수 있는 RESTful API를 제공함
  - 각 객체는 해당 API URI를 통해 고유하게 식별 가능
- SLA(Service-Level Agreement)
  - 서비스 수준 협약(SLA)는 서비스 제공자와 클라이언트 사이 맺어지는 계약임
  - S3 Standard-LA는 다음 SLA를 만족함
    - 여러 가용성 구역에 걸쳐 99.999999999%의 객체 내구성을 제공하도록 설계함
    - 하나의 가용성 구역 전체가 소실되어도 데이터 복원 가능
    - 연 간 99.9%의 가용성 제공

## 1단계 - 문제 이해 및 설계 범위 확정
- 요구 사항 분석
  - Q) 어떤 기능을 지원하는가?
    - A) 다음 기능을 제공하는 S3와 유사한 객체 저장소 시스템을 설계하고자 함
    - 버킷 생성
    - 객체 업로드 및 다운로드
    - 객체 버전
    - 버킷 내 객체 목록 출력 기능.
      - aws s3 ls 명령어와 유사
  - Q) 데이터의 크기는
    - A) 수 GB 이상 아주 큰 객체와 수 KB 정도의 다량의 소형 객체를 효율적으로 저장할 수 있어야 함 
  - Q) 매년 추가되는 데이터는 어느 정도인가?
    - A) 100PB
  - Q) 99.9999%의 데이터 내구성과 99.99%의 서비스 가용성을 보장한다고 하면 되는가?
    - A) 얍얍

### 비기능 요구 사항
- 100PB 데이터
- 식스 나인(six nines, 99.9999%) 수준의 데이터 내구성
- 포 나인(four nines, 99.99%) 수준의 서비스 가용성
- 저장 효율성
  - 높은 수준의 안정성과 성능은 보증하되 저장소 비용은 최대한 낮추어야 함

### 대략적인 규모 추정
- 객체 저장소는 디스크 용량이나 초당 디스크 IO(IOPS)가 병목이 될 가능성이 높음
  - 디스크 용량(가정)
    - 객체 가운데 20%는 크기가 1MB 미만의 작은 객체
    - 60% 정도의 객체는 1MB ~ 64MB 정도 크기의 중간 크기 객체다
    - 나머지 20% 정도는 64MB 이상의 대형 객체다
  - IOPS
    - SATA 인터페이스를 탑재하고 7200rpm을 지원하는 하드 디스크 하나가 초당 100~150회의 임의 데이터 탐색을 지원한다고 가정(100 ~ 150 IOPS)
- 계산을 쉽게하기 위해 중앙값을 사용
  - 소형 객체는 0.5MB
  - 중형 객체는 32MB
  - 대형 객체는 200MB
  - 40% 저장 공간 사용률을 유지하는 경우 저장소에 수용 가능한 객체의 수는 다음과 같음
    - 100PB = 100 * 1000 * 1000 * 1000MB = 10MB
    - 6억 8천만 개의 객체
      - 10^11 * 0.4 / (0.2 * 0.5MB + 0.6 * 32MB + 0.2 * 200MB)
    - 모든 객체의 메타데이터 크기가 대략 1KB 정도라고 가정하면 모든 메타데이터 정보를 저장하기 위해 0.68TB 정도의 공간이 필요함

## 2단계 - 개략적 설계안 제시 및 동의 구하기
- 알고 가면 좋은 객체 저장소의 몇 가지 속성
  - 객체 불변성
    - 객체 저장소와 다른 두 가지 유형의 저장소와 가장 큰 차이는 객체 저장소에 보관되는 객체는 변겨이 불가능하다는 것임
    - 삭제한 다음 새 버전 객체로 대체할 수는 있어도 그 값을 점진적으로 변경할 수 없음
  - key-value 저장소
    - 객체 저장소를 사용하는 경우 해당 객체의 URI를 사용해 데이터를 가져올 수 있음
    - URI는 키, 데이터는 값이므로 key-value 저장소라고 볼 수 잇음
  - 저장은 1회 읽기는 여러번
    - 데이터 접근 패턴 측명에서 보면 쓰기는 1회, 읽기는 여러 번 발생함
    - 링크드인의 조사에 따르면 객체 저장소에 대한 요청 가운데 95% 정도가 읽기 요청임
  - 소형 및 대형 객체 동시 지원
    - 다양한 크기의 객체를 문제 없이 저장할 수 있음
- 객체 저장소의 설계 철학은 UNIX 파일 시스템의 설계 철학과 아주 비슷함
- UNIX는 파일을 로컬 파일 시스템에 저장하면 파일의 이름과 데이터는 같은 곳에 저장되지 않음
  - 파일 이름을 아이노드라고 불리는 자료 구조에 저장하고 파일의 데이터는 디스크의 다른 위치에 들어감
  - 아이노드에는 파일의 데이터가 실제로 보관되는 디스크 상의 위치를 가리키는 파일 블록 포인터 목록이 저장됨
  - 따라서 파일을 읽을 때 우선 아이노드에 기록된 메타데이터를 읽어서 파일 블록 포인터 목록을 확보한 이후 그 포인터를 일일이 따라가 데이터를 읽어야 함
- 객체 저장소의 동작 방식도 비슷함
  - 메타데이터 저장소는 아이노드에 해당하고, 객체 데이터가 저장되는 데이터 저장소는 하드 디스크에 해당함
  - 다만 파일 블록포인터 대신 네트워크를 통해 데이터 저장소에 보관된 개겣를 요청하는 데 필요한 식별자(ID)가 보관됨
- 메타데이터와 객체의 실제 데이터를 분리하면 설계가 단순해짐
  - 데이터 저장소에 보관되는 데이터는 불변이고, 메타데이터는 변경이 가능함
  - 분리하면 두 컴포넌트는 독립적으로 구현하고 최적화할 수 있음

### 개략적 설계안
- 중요 컴포넌트
  - 로드밸런서
    - RESTful API에 대한 요청을 API 서버들에 분산하는 역할
  - API 서비 
    - IAM 서비스, 메타데이터 서비스, 저장소 서비스에 대한 호출을 조율하는 역할을 담당
    - 무상태 서비스라서 수평적 확장 가능
  - IAM 서비스
    - 인증(authetication), 권한 부여(authorization), 접근 제어 등을 중앙에서 맡아서 처리
  - 데이터 저장소
    - 실제 데이터를 보관하고 피룡할 때마다 읽어가는 저장소.
    - 모든 데이터 관련 연산은 객체 ID(UUID)를 통함
  - 메타데이터 저장소
    - 객체 메타데이터를 보관하는 장소
  - 메타데이터 저장소와 데이터 저장소는 논리적인 구분일 뿐이며 구현 방법은 여러 가지가 있을 수 있음
  - 가장 중요한 작업 흐름
    - 객체 업로드
    - 객체 다운로드
    - 객체 버전 및 버킷 내 모든 객체 목록 출력

### 객체 업로드
- 객체는 버킷 안에 두어야 함
- 총 7단계
  - 클라이언트는 bucket-to-share 버킷을 생성하기 위한 HTTP PUT 요청을 보내고, API 서비스로 전달됨
  - API 서비스는 IAM을 호출해 해당 사용자가 WRITE 권한을 가졌는지 확인함
  - API 서비스는 메타데이터 DB에 버킷 정보를 등록하기 위한 메타 데이터 저장소를 호출함
    - 버킷 정보가 만들어지면 그 사실을 알리는 메시지가 클라이언트에 전송됨
  - 버킷이 만들어진 후 클라이언트는 script.txt 객체를 생성하기 위한 HTTP PUT 요청을 보냄
  - API 서비스는 해당 사용자 신원 및 WRITE 권한 소유 여부를 확인
  - 확인 결과 문제 없으면 API 서비스는 HTTP PUT 요청 body에 실린 객체 데이터를 데이터 저장소로 보냄
    - 데이터 저장소는 해당 객체로 저장하고 해당 객체의 UUID를 반한함
  - API 서비스는 메타데이터를 호출해서 새로운 항목을 등록.
    - object_id(UUID), bucket_id(해당 객체가 속한 버킷), object_name 등의 정보가 포함됨

### 객체 다운로드
- 디렉토리 같은 계층 구조를 지원하지 않음
- 버킷 이름과 객체 이름을 연결하면 폴더 구조를 흉내 내는 논리적 계층을 만들 수는 있음
- 데이터 저장소는 객체 이름을 보관하지 않고 object_id(UUID)를 통한 객체 연산만 지원함
  - 객체를 다운로드하려면 객체 이름을 UUID로 변환해야 함
- 객체 다운로드 프로세스
  - 클라이언트는 GET /bucket-to-share/script.txt 요청을 로드밸런서로 보냄.
    - 로드밸런서는 이 요청을 API 서버로 보냄
  - API 서비스는 LAM을 질의해 사용자가 해당 버킷에 READ 권한을 갖고 있는지 확인
  - 권한이 있음을 확인하면 API 서비스는 해당 객체의 UUID를 메타데이터 저장소에서 가져옴
  - API 서비스는 해당 UUID를 사용해 데이터 저장소에서 객체 데이터를 가져 옴
  - API 서비스는 HTTP GET 요청에 대한 응답으로 해당 객체 데이터를 반환함

## 3단계 - 세부 설계
### 데이터 저장소
- API 서비스는 사용자 요청을 받으면 그 요청을 처리하기 위해 다른 내부 서비스들을 호출함
- 객체를 저장하거나 가져오는 작업은 데이터 저장소를 호출해 처리함

### 데이터 라우팅 서비스
- 라우팅 서비스는 데이터 노드 클러스터에 접근하기 위한 RESTful API 혹은 gRPC 서비스를 제공함
- 무상태 서비스
- 역할
  - 배치 서비스(placement service)를 호출해 데이터를 저장할 최적의 데이터 노드를 판단
  - 데이터 노드에서 데이터를 읽어 API 서비스에 반환
  - 데이터 노드에서 데이터 기록

### 배치 서비스
- 어느  데이터 노드에 데이터를 저장할지 결정하는 역할을 담당
- 주 데이터 노드와 부 데이터 노드가 있음
- 내부적으로 가상 클러스터 지도(virtual cluster map)를 유지함
- 지도에는 클러스터의 물리적 형상 정보가 보관됨
- 배치 서비스는 이 지도에 보관되는 데이터 노드의 위치 정보를 이용해 데이터 사본(replica)이 물리적으로 다른 위치에 놓이도록 함
- 물리적인 분리는 높은 데이터 내구성을 달성하는 핵심 요소임
- 배치 서비스는 모든 데이터 노드와 지속적으로 박동 메시지를 주고받으며 상태를 모니터링 함
- 15초의 유예기간(grace period) 동안 박동 메시지에 응답하지 않을 경우 죽은 노드로 표시함
- 배치 서비스는 아주 중요해서 5개 ~ 7개의 노드를 갖는 배치 서비스 클러스터를 팩서스나 래프트 같은 합의 프로토콜(consensus protocol)을 사용해 구축할 것을 권장함
  - 합의 프로토콜은 일부 노드에 장애가 생겨도 절반 이상이 건강하면 서비스를 지속하게 보장함

### 데이터 노드
- 실제 객체 데이터가 보관되는 곳
- 다중화 그룹
  - 여러 노드에 데이터를 복제해 데이터의 안정성과 내구성을 보증함.
- 각 데이터 노드에는 배치 서비스에 주기적으로 박동 메시지를 보내는 서비스 데몬이 있음
  - 해당 데이터 노드에 부착된 디스크 드라이브(HDD/SSD)의 수
  - 각 드라이브에 저장된 데이터의 양
- 배치 서비스는 못 보던 데이터 노드에서 박동 메시지를 처음 받으면 해당 노드에 ID를 부여하고 가상 클러스터 지도에 추가한 후 아래 정보를 반환함
  - 해당 데이터 노드에 부여한 고유 식별자
  - 가상 클러스터 지도
  - 데이터 사본을 보관할 위치

### 데이터 저장 흐름
- 데이터 노드에 데이터가 영속적으로 보관되는 흐름
  - API 서비스는 객체 데이터를 데이터 저장소로 포워딩함
  - 데이터 라우팅 서비스는 해당 객체에 UUID를 할당하고 배치 서비스에 해당 객체를 보관할 데이터 노드를 질의함
    - 배치 서비스는 가상 클러스터 지도를 참조해 해당 객체를 보관할 주 데이터 노드를 반환함
  - 데이터 라우팅 서비스는 저장할 데이터를 UUID와 함께 주 데이터 노드에 직접 전송함
  - 주 데이터 노드는 데이터를 자기 노드에 지역적으로 자장하고, 두 개의 부 데이터 노드에 다중화함.
    - 주 데이터 노드는 데이터를 모든 부 데이터 노드에 성공적으로 다중화한 후에는 데이터 라우팅 서비스에 응답을 보냄
  - 객체의 UUID(객체의 ID)를 API 서비스에 반환함
- 2 단계는 배치 서비스에 UUID를 입력으로 주고 질의하면 해당 객체에 대한 다중화 그룹이 반환된다는 뜻임
  - 계산 결과는 결정적(deterministric)이어야하고, 다중화 그룹이 추가되거나 삭제되는 경우에도 유지되어야 함
  - 이런 종류의 조회 연산 구현에는 보통 안정 해시(consistent hash)를 사용함
- 4단계는 응답을 반환하기 전 데이터를 모든 부 노드에 다중화한다는 뜻임
  - 모든 데이터 노드에 강력한 일관성이 보장됨
  - 가장 느린 사본에 작업이 완료될 때까지 응답이 반환되지 못해 지연 시간 측면에서 손해임

![img.png](img.png)
- 첫 선택지는 데이터를 세 노드에 전부 보관하면 성공적으로 보관했다고 간주함
  - 데이터 일관성에서는 최선이지만, 응답 지연이 가장 높음
- 두 번째는 데이터를 주 데이터 및 두 개의 부 노드 가운데 하나에 성공적으로 보관하면 성공이라고 간주함
  - 중간 정도의 데이터 일관성 및 응답 지연을 제공함
- 세 번째는 데이터를 주 데이터에 보관하면 성공이라고 간주함
  - 데이터 일관성 측면에서는 최악이지만 응답 지연은 가장 낮음

### 데이터는 어떻게 저장되는가
- 데이터 노드가 실제로 데이터를 어떻게 관리하는가?
  - 가장 단순한 방법은 각각의 객체를 개별 파일로 저장하는 것임
  - 잘 동작하지만, 작은 파일이 많아지면 성능이 떨어짐
  - 작은 파일이 많아질 경우 문제점
    - 낭비되는 데이터 블록 수가 늘어남
      - 파일 시스템은 파일을 별도 디스크 블록으로 저장함
      - 디스크 블록의 크기는 전부 같고 볼륨 초기화 시 결정되는데, 보통 4KB임
      - 4KB보다 작은 파일을 저장할 때에도 블록 하나를 온전히 씀
      - 따라서 작은 파일이 많아지면 낭비되는 블록이 늘어남
    - 아이노드 용량 한계를 초과하는 문제
      - 파일 시스템은 파일 위치 등의 정보를 아이노드라는 특별한 유형의 블록에 저장함
      - 대부분의 파일 시스템의 경우 사용 가능한 아이도느 수는 디스크 초기화 순간 결정됨
      - 작은 파일 수가 수백만개에 달하면 아이노드가 전부 소진될 수 있음.
      - 운영 체제는 파일 시스템 메타데이터를 공격적으로 캐싱하는 전략을 취해도 아주 많은 양의 아이노드를 효과적으로 처리하지 못 함
      - 따라서 작은 객체를 개별 파일 형태로 저장하는 방안은 현실에서 쓸모가 없음
  - 이런 문제는 작은 객체들을 큰 파일 하나로 모아서 해결 가능함
  - 개념적으로 WAL(Write Ahead Log)와 같이 이미 존재하는 파일에 추가하는 방식임
    - WAL은 4장 "분산 메시지 큐"를 참고하기
  - 용량 임계치에 도달한 파일(보통 수 GB)은 읽기 전용 파일로 변경하고 새로운 파일을 만듦
  - 읽기-쓰기 파일에 대한 쓰기 연산은 순차적으로 이루어져야 한다.

### 객체 소재 확인
- 각 데이터 파일 안에 많은 작은 객체가 들어있을 때 UUID로 객체 위치를 찾는 방법
  - 객체가 보관된 데이터 파일
  - [데이터 파일 내 객체 오프셋(offset)](#q-uuid로-객체-위치-찾을-때-오프셋이-필요한-이유는-무엇이고-오프셋은-무엇인가)
  - 객체 크기
- 위의 데이터들을 가진 DB 스키마는 RocksDB같은 파일 기반 key-value 저장소를 사용하는 방법과 RDB를 사용하는 방법이 있다.
  - RocksDB는 SSTable에 기반한 방법으로 쓰기는 좋지만 읽기가 느리다.
  - RDB는 B+ 트리 기반으로 저장하며 읽기는 좋지만 쓰기는 느리다.
- 객체 위치를 저장하는 테이블의 데이터 양은 막대함
  - 데이터 노드에 저장되는 위치 데이터는 다른 데이터 노드와 공유할 필요가 없음
    - 각 데이터 노드마다 RDB를 설치하는 방법도 가능함
    - SQLite 같은 경량 DB를 사용하면 좋음

### 개선된 데이터 저장 흐름
- API 서비스는 새로운 객체를 저장하는 요청을 데이터 노드 서비스에 전송함
- 데이터 노드 서비스는 해당 객체를 읽기-쓰기 파일 /data/c의 마지막 부분에 추가함
- 해당 객체에 대한 새로운 레코드를 object_mapping 테이블에 추가함
- 데이터 노드 서비스는 API 서비스의 해당 객체의 UUID를 반환함

### 데이터 내구성
- six nines(99.9999%) 수준의 데이터 내구성을 보장하기 위해서는 장애가 발생할 모든 경우를 세심하게 살피고 여러 데이터를 적절히 다중화해야 한다.

### 데이터 다중화 - 하드웨어 장애와 장애 도메인
- 하드 디스크 장애는 피할 수 없음
- 드라이브 한 대로는 내구성 목표를 달성할 수 없을 가능성이 높음
- 데이터를 여러 대의 드라이브에 복제
  - 여기선 3중으로 복제함
  - 데이터 3중 복제 시 내구성은 약 0.999999이다.
- 장애 도메인은 서비스에 문제가 발생했을 때 부정적인 영향을 받는 물리적/논리적 구획을 말함
- 데이터 센터의 가용성 구역은 대표적인 대규모 장애 도메인 사례다.
  - 데이터를 여러 AZ에 복제해 장애 여파를 최소화 할 수 잇음

### 데이터 다중화 - 소거 코드(erasure coding)
- 3중 데이터 다중화는 대략 99.9999%의 내구성을 달성
- 다른 방법 중 소거 코드가 있음
- 데이터를 작은 단위로 분할해 다른 서버에 배치하고, 일부가 소실되었을 때 복구하기 위해 패리티라는 정보를 만들어 중복성을 확보함
  - 4 + 2 소거 코드 사례
    - 데이터를 4개의 같은 크기 단위로 분할
    - 수학 공식을 사용해 패리티 p1, p2를 계산.
      - p1 = d1 + 2 * d2 - d3 + 4 * d4
      - p2 = -d1 + 5 * d3 - 3 * d4
    - - 데이터 d3와 d4가 노드 장애로 소실되었을 때
    - 남은 값 d1, d2, p1, p2와 페리티 계산에 쓰인 수식을 결합해 d3와 d4를 복원 가능함
  - 소거 코드를 사용하면 최대 8개의 건강한 노드에서 데이터를 가져와야할 수 있다.
    - 소거 코드를 추가하면 2개의 데이터 블록에 하나의 패리티 블록이 필요하므로 50% 오버헤드가 발생한다.
    - 3중화는 200% 오버헤드가 발생함

|--| 다중화 | 소거 코드 |
|--|--|--|
| 저장소 효율성 | 200%의 저장 용량 오버헤드 | 50%의 저장 용량 오버헤드. |
| 계산 자원 | 계산이 필요 없음 | 패티리 계산에 많은 계산 자원 소모 |
| 쓰기 성능 | 데이터를 여러 노드에 복제. 추가로 필요한 계산 없음. | 데이터를 디스크에 기록하기 전 패리티 곘나이 필요해 쓰기 연산의 응답 지연 증가 |
| 읽기 성능 | 장애가 발생하지 않은 노드에서 데이터를 읽음 | 데이터를 읽어야 할 때마다 클러스터 내의 여러 노드에 데이터를 가져와야 함. 장애 발생 시 빠진 데이터 복원이 필요해 지연 시간 증가 |

- 응답 지연이 중요할 땐 다중화가, 저장소 비용이 중요할 땐 소거 코드가 유리함
- 소거 코드는 비용과 내구성 측면에서 매력적이지만 데이터 노드 설계에서 까다로움

### 데이터 다중화 - 정확성 검증
- 대규모 시스템은 디스크 훼손이 아니라 메모리의 데이터가 망가지는 일도 빈번하다
- 메모리 데이터 훼손은 프로세스 경계에 데이터 검증을 위한 체크섬을 두어 해결할 수 있다.
  - 새로 계산한 체크섬이 원본 체크섬과 다르면 데이터가 망가진 것
  - 같은 경우에는 아주 높은 확률로 데이터가 온전함
  - 같다고 온전하지 않을 수 있지만 아주 낮은 확률이기에 현실적으로 같다고 함
  - 체크섬에는 MD5, SHA1, HMAC 등 다양한 알고리즘이 존재함
- 체크섬과 (8 + 4) 소거 코드 사용 시 절차
  - 객체 데이터와 체크섬을 가져옴
  - 수신된 데이터의 체크섬을 계산
    - 두 체크섬이 일치하면 데이터에는 에러가 없다고 간주
    - 체크섬이 다르면 데이터가 망가진 것이므로 다른 장애 도메인에서 데이터를 가져와 복구를 시도
  - 데이터 8조각을 전부 수신할 때까지 1, 2를 반복해 원래 객체를 복원한 후 클라이언트에게 보냄

### 메타데이터 데이터 모델 - 스키마
- 지원해야하는 질의 3가지
  - 객체 이름으로 객체 ID 찾기
  - 객체 이름에 기반해 객체 삽입 또는 삭제
  - 같은 접두어를 갖는 버킷 내의 모든 객체 목록 확인

### 메타데이터 데이터 모델 - bucket 테이블의 규모 확장
- 보통 한 사용자가 만들 수 있는 버킷은 제한이 있어 이 테이블의 크기는 작음
- 100만명의 고객이 각자 10개의 버킷을 갖고 있고 한 레코드의 크기가 10KB라고 가정
  - 10GB(100만 * 10 * 10KB) = 100GB
  - 최신 DB 한 대에 충분히 저장 가능
  - 하지만, 모든 읽기 요청을 처리하기에는 CPU 용량이나 네트워크 대역폭이 부족할 수 있음
  - DB 사본을 만들어 읽기 부하 분산이 필요함

### object 테이블의 규모 확장
- object 테이블에는 객체 메타데이터를 보관함
- 객체 메타 데이터를 DB 서버 한 대에 보관할 수 없음
  - 샤딩을 통해 테이블 규모를 확장함
  - bucket_id를 기준으로 같은 버킷 내 객체는 같은 샤드에 배치되게 함
    - 3가지 질의 중 1, 2 질의를 효율적으로 지원하지 못 함
      - URI를 기준으로 하기 때문
  - bucket_name과 object_name을 결합해 샤딩
    - 대부분 메타데이터 관련 연산이 객체 URI를 기준으로 함
      - 객체 ID 검색도 객체 URI를 기준으로하고, 객체 업로드도 마찬가지임
    - bucket_name과 데이터를 균등하게 분산하기 위해서는 object_name의 순서쌍을 해싱한 값을 샤딩 키로 사용하면 됨
    - 이럴 경우 3번째 질의가 다소 애매할 수 있음

### 버킷 내 객체 목록 확인
- 객체 저장소는 파일 시스템처럼 계층적 구조로 보관하지 않음
- 객체는 s3://<버킷 이름>/<객체 이름>의 수평적 경로로 접근함
- s3는 사용자가 객체를 잘 정리할 수 있게 접두어를 지원함.
  - 접두어를 잘 사용하면 디렉토리와 비슷하게 데이터를 정리할 수 있음.


### Q) UUID로 객체 위치 찾을 때 오프셋이 필요한 이유는 무엇이고, 오프셋은 무엇인가?
