# 13장 - 검색어 자동완성 시스템
## 1단계 - 문제 이해 및 설계 범위 확정
- 요구 사항 구체화
  - Q) 사용자가 입력하는 단어는 자동완성될 단어의 첫 부분이어야 하는지, 중간도 되는지?
    - A) 첫 부분으로 한정함
  - Q) 몇 개의 자동완성 검색어가 표시되어야 함?
      - A) 5개
  - Q) 해당 5개의 검색어를 고르는 기준은?
      - A) 질의 빈도에 따라 정해지는 검색어 인기 순위를 기준으로 함
  - Q) 맞춤법 검사 기능도 제공하나?
      - A) 아님. 맞춤법 검사나 자동수정은 지원하지 않음
  - Q) 질의는 영어인가?
      - A) 맞음, 하지만 시간이 허락하면 다국어 지원을 생각해도 좋음
  - Q) 대문자나 특수 문자 처리도 해야하나?
      - A) 아님. 모든 질의는 영어 소문자로 이루어진다고 가정함
  - Q) 얼마나 많은 사용자를 지원해야 하는가?
      - A) DAU 기준으로 천만명임
- 요구사항
  - 빠른 응답 속도
  - 연관성
  - 정렬
  - 규모 확장성
  - 고가용성

### 개략적 규모 측정
- DAU는 천만 명으로 가정
- 한 사용자는 평균 매일 10건의 검색을 수행한다고 가정 
- 질의마다 평균 20바이트의 데이터를 입력한다고 가정
  - 인코딩은 ASCII를 사용한다고 가정해서 1문자 = 1바이트
  - 질의문은 평균적으로 4개 단어로 이루어진다고 가정하며, 각 단어는 평균적으로 다섯 글자로 구성된다고 가정
  - 질의당 평균 4 * 5 = 20바이트
- 검색창에 글자 입력마다 API를 호출함.
  - 평균 1회 검색에 20건의 요청이 발생
- 초당 대략 24_000건의 질의(QPS)가 발생함
  - 10_000_000 user * 10질의/일 * 20자/24시간/3_600초
- 최대 QPS = QPS * 2 -> 대략 48_000
- 질의 가운데 20% 정도는 신규 검색어라고 가정
  - 대략 0.4GB
    - 10_000_000 user * 10질의/일 * 20자 * 20%
    - 매일 0.4GB의 신규 데이터가 시스템에 추가됨

## 2단계 - 개략적 설계안 제시 및 동의 구하기
### 데이터 수집 서비스
- 사용자가 입력한 질의를 실시간으로 수집하는 시스템
- 질의문과 사용 빈도를 저장하는 빈도 테이블로 구성됨.

### 질의 서비스
- 질의를 하고, 상위 Top5 자동완성 검색어를 알려주는 서비스


## 3단계 - 상세 설계
### 트라이(trie) 자료구조
- RDB는 가장 인기 있는 5개의 질문을 뽑는데 비효율적임.
- 트라이(trie, 접두어 트리 prefix tree)
  - retrieval이라는 단어에서 옴
  - 문자열을 꺼내는 연산에 초점을 맞추어 설계된 자료구조임
    - 루트 노드는 빈 문자열을 나타냄
    - 각 노드에는 글자(character) 하나를 저장하며, 26개(해당 글자 다음에 등장할 수 있는 모든 글자의 수)의 자식 노드를 가질 수 있음
    - 각 트리 노드는 하나의 단어, 또는 접두어 문자열(prefix string)을 나타냄
    - 기본적으로 트라이 자료구조는 노드에 문자들을 저장함.
      - 이용 빈도에 따라 정렬된 결과를 내놓기 위해 빈도 정보도 함께 저장
    - 용어 정의
      - p : 접두어(prefix)의 길이
      - n : 트라이 안에 있는 노드 개수
      - c : 주어진 노드의 자식 노드 개수
  - 가장 많이 사용된 질의어 k개를 찾는 과정
    - 해당 접두어를 표현하는 노드를 찾음.
      - 시간 복잡도는 O(p)
    - 해당 노드부터 시작하는 하위 트리를 탐색해 모든 유효 노드를 찾음.
      - 유효 노드 : 유효한 검색 문자열을 구성하는 노드
        - 시간 복잡도는 O(c)
    - 유효 노드들을 정렬해 가장 인기 있는 검색어 k개를 찾음
      - 시간 복잡도는 O(clogc)
    - 직관적인 알고리즘이지만, 최악의 경우 k개 결과를 얻으려고 전체 트라이를 다 검색해야 하는 일이 생길 수 있음.
      - 해결 방법
        - 접두어의 최대 길이를 제한
        - 각 노드에 인기 검색어를 캐시

- **접두어 최대길이 제한**
  - 사용자가 검색창에 긴 검색어를 입력하는 일은 거의 없음
  - 따라서 p 값은 작은 정숫값이라고 가정해도 안전함
  - 검색서 최대 길이를 제한하면 '접두어 찾기' 단계의 복잡도는 O(p)에서 O(1) 가까이 갈 수 있다
- **노드에 인기 검색어를 캐시**
  - 각 노드넹 k개의 인기 검색어를 캐시해두면 전체 트라이를 검색하는 일을 방지할 수 있다.
  - 5 ~ 10개 정도의 자동 완성 제안을 표시하면 충분하므로, k는 아주 작은 값임.
  - 각 노드에 질의어를 저장할 공간이 많이 사용된다는 단점이 있음.
    - 빠른 응답속도가 중요할 경우에는 저장공간을 희생할 가치가 있음.

### 데이터 수집 서비스
- 사용자가 추천 검색어 API를 호출할 때마다 실시간으로 데이터를 수정하는 것은 실용적이지 못함.
  - 매일 수천만 건의 질의가 입력되는데, 그때마다 트라이를 갱신하면 질의 서비스가 심각하게 느려짐
  - 일단 트라이가 만들어진 이후 인기 검색어는 그다지 자주 바뀌지 않으므로 트라이를 그렇게 자주 갱신할 필요성이 낮음
- 규모 확장이 쉬운 서비스를 만들기 위해서는 서비스 유형도 중요함.
- 트라이를 만드는 데 사용되는 데이터는 보통 데이터 분석 서비스나 로깅 서비스로부터 올 가능성이 높음

### 데이터 수집 서비스 - 데이터 분석 서비스 로그
- 검색창에 입력된 질의에 대한 원본 데이터가 보관됨.
- 새로 추가되기만 하며 수정은 이루어지지 않음
- 로그 데이터에 인덱스를 걸지 않음

### 데이터 수집 서비스 - 로그 취합 서버
- 데이터 분석 서비스에서 나오는 로그는 보통 양이 엄청나고 데이터 형식이 제각각임
  - 이 데이터를 잘 취합해(aggregation) 소비하기 쉽게 만드렁야 함

### 데이터 수집 서비스 - 작업 서버
- 작업 서버(worker)는 주기적으로 비동기적 작업(job)을 실행하는 서버 집합
- 트라이 자료구조를 만들고 트라이 데이터베이스에 저장하는 역할을 담당

### 데이터 수집 서비스 - 트라이 캐시
- 트라이 캐시는 분산 캐시 시스템으로 트라이 데이터를 메모리에 유지해 읽기 연산 성능을 높이는 구실을 함
- 매주 트라이 DB의 스냅샷을 떠서 갱신

### 데이터 수집 서비스 - 트라이 DB
- 지속성 저장소
- 사용할 수 있는 선택지
  - 문서 저장소(document store)
    - 새 트라이를 매주 만드므로 주기적으로 트라이를 직렬화해 DB에 저장 가능
    - 몽고디비 같은 문서 저장소를 사용하면 편리함
  - key-value
    - 트라이는 해시 테이블 형태로 변환 가능
      - 트라이에 보관된 모든 접두어를 해시 테이블의 key로 변환
      - 각 트라이 노드에 저장된 모든 데이터를 해시 테이블 value로 변환
      - 각 노드가 하나의 <key, value> 상으로 변환

### 질의 서비스
- 사용자가 요청하면 [로드 밸런서 -> API 서버 -> 트라이 캐시 -> 트라이 DB] 를 거침
  - 검색 질의가 로드 밸런서로 전송
  - 로드밸런서가 해당 질의를 API 서버로 보냄
  - API 서버는 트라이 캐시에서 데이터를 가져와 해당 요청에 대한 자동완성 검색어 제한 응답을 구성
  - 데이터가 트라이 캐시에 없는 경우 DB에서 가져와 캐시를 채움
    - 캐시 미스는 캐시 서버의 메모리가 부족하거나 캐시 서버에 장애가 있어도 발생함
- 질의 서비스는 아주 빨라야 함.
  - AJAX 요청
    - 브라우저는 보통 AJAX 요청을 보내 자동완성된 검색어 목록을 가져옴
  - 브라우저 캐싱
    - 대부분 애플리케이션은 자동완성 검색어 제안 결과가 짧은 시간에 자주 바뀌지 않음
    - 이전에 제안된 검색어들을 브라우저 캐시에 넣어두면 빠르게 사용할 수 있다.
  - 데이터 샘플링
    - 대규모 시스템의 경우 모든 질의 결과를 로깅하도록 하면 CPU와 저장공간이 엄청나게 소진됨.
    - N개의 요청 가운데 1개만 로깅하도록하는 방법을 사용하면 유용함


### 트라이 연산
### 트라이 연산 - 트라이 생성
- 트라이 생성은 작업 서버가 담당하며, 데이터 분석 서비스의 로그나 DB로부터 취합된 데이터를 이용

### 트라이 연산 - 트라이 갱신
- 매주 1회 갱신
  - 새로운 트라이를 만든 후 기존 트라이를 대체
- 트라이의 각 노드를 개별적으로 갱신하는 방법
  - 성능이 좋지 않음
  - 트라이가 작을 경우에는 효율적일 수 있음.
  - 노드 갱신 시 상위 노드도 생긴해야함.

### 트라이 연산 - 검색어 삭제
- 혐오, 폭력성, 성적 등 위험한 질의어를 자동완성 결과에서 제거해야 함
- 트라이 캐시 앞에 필터 계층(filter layer)를 사용
- DB에서 해당 검색어 삭제는 다음 업데이트 사이클에 비동기로 진행하면 됨

### 규모 확장이 가능한 저장소
- 영어만 지원하면 되기에 첫 글자 기준으로 샤딩할 수 있음.
  - 다만, 각 알파벳에 해당하는 단어가 균등하지 않기에 균등 배분이 쉽지 않음
- 과거 질의 데이터의 패턴을 분석해 샤딩할 수 잇음

## 4단계 - 마무리
- Q) 다국어 지원ㅇ하려면 시스템을 어떻게 확장해야하는가?
  - 비영어권의 국가를 지원하려면 트라이에 유니코드 형태의 데이터를 저장해야 함.
- Q) 국가별로 인기 검색어 순위가 다를 경우?
  - 국가 별로 다른 트라이를 사용하고, 트라이를 CDN에 저장해 응답속도를 높일 수 있음.
- Q) 실시간으로 변하는 검색어의 추이를 반영하려면 어떡하는가?
  - 현 설계안에서는 적합하지 않음.
    - 작업 서버가 매주 1회 돌기에 적절하게 트라이 갱신이 어려움.
    - 트라이 구성에 너무 많은 시간이 소요됨.
  - 샤딩을 통해 작업 대상 데이터의 양을 줄임
  - 순위 모델(ranking model)을 바꿔 최근 검색어에 가중치 부여
  - 데이터가 스트림 형태로 올 수 있음.
    - 한 번에 모든 데이터를 동시에 사용할 수 없을 가능성이 존재함.
    - 데이터 스트리밍 -> 데이터가 지속적으로 생성됨.
      - 아파치 하둡 맵리듀스, 아파치 스파크 스트리밍, 아파치 스톰, 아파치 카프카 등의 시스템