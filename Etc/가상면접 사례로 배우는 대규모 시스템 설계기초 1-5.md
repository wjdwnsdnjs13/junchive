# 13장 - 검색어 자동완성 시스템
## 1단계 - 문제 이해 및 설계 범위 확정
- 요구 사항 구체화
  - Q) 사용자가 입력하는 단어는 자동완성될 단어의 첫 부분이어야 하는지, 중간도 되는지?
    - A) 첫 부분으로 한정함
  - Q) 몇 개의 자동완성 검색어가 표시되어야 함?
    - A) 5개
  - Q) 해당 5개의 검색어를 고르는 기준은?
    - A) 질의 빈도에 따라 정해지는 검색어 인기 순위를 기준으로 함
  - Q) 맞춤법 검사 기능도 제공하나?
    - A) 아님. 맞춤법 검사나 자동수정은 지원하지 않음
  - Q) 질의는 영어인가?
    - A) 맞음, 하지만 시간이 허락하면 다국어 지원을 생각해도 좋음
  - Q) 대문자나 특수 문자 처리도 해야하나?
    - A) 아님. 모든 질의는 영어 소문자로 이루어진다고 가정함
  - Q) 얼마나 많은 사용자를 지원해야 하는가?
    - A) DAU 기준으로 천만명임
- 요구사항
  - 빠른 응답 속도
  - 연관성
  - 정렬
  - 규모 확장성
  - 고가용성

### 개략적 규모 측정
- DAU는 천만 명으로 가정
- 한 사용자는 평균 매일 10건의 검색을 수행한다고 가정
- 질의마다 평균 20바이트의 데이터를 입력한다고 가정
  - 인코딩은 ASCII를 사용한다고 가정해서 1문자 = 1바이트
  - 질의문은 평균적으로 4개 단어로 이루어진다고 가정하며, 각 단어는 평균적으로 다섯 글자로 구성된다고 가정
  - 질의당 평균 4 * 5 = 20바이트
- 검색창에 글자 입력마다 API를 호출함.
  - 평균 1회 검색에 20건의 요청이 발생
- 초당 대략 24_000건의 질의(QPS)가 발생함
  - 10_000_000 user * 10질의/일 * 20자/24시간/3_600초
- 최대 QPS = QPS * 2 -> 대략 48_000
- 질의 가운데 20% 정도는 신규 검색어라고 가정
  - 대략 0.4GB
    - 10_000_000 user * 10질의/일 * 20자 * 20%
    - 매일 0.4GB의 신규 데이터가 시스템에 추가됨

## 2단계 - 개략적 설계안 제시 및 동의 구하기
### 데이터 수집 서비스
- 사용자가 입력한 질의를 실시간으로 수집하는 시스템
- 질의문과 사용 빈도를 저장하는 빈도 테이블로 구성됨.

### 질의 서비스
- 질의를 하고, 상위 Top5 자동완성 검색어를 알려주는 서비스


## 3단계 - 상세 설계
### 트라이(trie) 자료구조
- RDB는 가장 인기 있는 5개의 질문을 뽑는데 비효율적임.
- 트라이(trie, 접두어 트리 prefix tree)
  - retrieval이라는 단어에서 옴
  - 문자열을 꺼내는 연산에 초점을 맞추어 설계된 자료구조임
    - 루트 노드는 빈 문자열을 나타냄
    - 각 노드에는 글자(character) 하나를 저장하며, 26개(해당 글자 다음에 등장할 수 있는 모든 글자의 수)의 자식 노드를 가질 수 있음
    - 각 트리 노드는 하나의 단어, 또는 접두어 문자열(prefix string)을 나타냄
    - 기본적으로 트라이 자료구조는 노드에 문자들을 저장함.
      - 이용 빈도에 따라 정렬된 결과를 내놓기 위해 빈도 정보도 함께 저장
    - 용어 정의
      - p : 접두어(prefix)의 길이
      - n : 트라이 안에 있는 노드 개수
      - c : 주어진 노드의 자식 노드 개수
  - 가장 많이 사용된 질의어 k개를 찾는 과정
    - 해당 접두어를 표현하는 노드를 찾음.
      - 시간 복잡도는 O(p)
    - 해당 노드부터 시작하는 하위 트리를 탐색해 모든 유효 노드를 찾음.
      - 유효 노드 : 유효한 검색 문자열을 구성하는 노드
        - 시간 복잡도는 O(c)
    - 유효 노드들을 정렬해 가장 인기 있는 검색어 k개를 찾음
      - 시간 복잡도는 O(clogc)
    - 직관적인 알고리즘이지만, 최악의 경우 k개 결과를 얻으려고 전체 트라이를 다 검색해야 하는 일이 생길 수 있음.
      - 해결 방법
        - 접두어의 최대 길이를 제한
        - 각 노드에 인기 검색어를 캐시

- **접두어 최대길이 제한**
  - 사용자가 검색창에 긴 검색어를 입력하는 일은 거의 없음
  - 따라서 p 값은 작은 정숫값이라고 가정해도 안전함
  - 검색서 최대 길이를 제한하면 '접두어 찾기' 단계의 복잡도는 O(p)에서 O(1) 가까이 갈 수 있다
- **노드에 인기 검색어를 캐시**
  - 각 노드넹 k개의 인기 검색어를 캐시해두면 전체 트라이를 검색하는 일을 방지할 수 있다.
  - 5 ~ 10개 정도의 자동 완성 제안을 표시하면 충분하므로, k는 아주 작은 값임.
  - 각 노드에 질의어를 저장할 공간이 많이 사용된다는 단점이 있음.
    - 빠른 응답속도가 중요할 경우에는 저장공간을 희생할 가치가 있음.

### 데이터 수집 서비스
- 사용자가 추천 검색어 API를 호출할 때마다 실시간으로 데이터를 수정하는 것은 실용적이지 못함.
  - 매일 수천만 건의 질의가 입력되는데, 그때마다 트라이를 갱신하면 질의 서비스가 심각하게 느려짐
  - 일단 트라이가 만들어진 이후 인기 검색어는 그다지 자주 바뀌지 않으므로 트라이를 그렇게 자주 갱신할 필요성이 낮음
- 규모 확장이 쉬운 서비스를 만들기 위해서는 서비스 유형도 중요함.
- 트라이를 만드는 데 사용되는 데이터는 보통 데이터 분석 서비스나 로깅 서비스로부터 올 가능성이 높음

### 데이터 수집 서비스 - 데이터 분석 서비스 로그
- 검색창에 입력된 질의에 대한 원본 데이터가 보관됨.
- 새로 추가되기만 하며 수정은 이루어지지 않음
- 로그 데이터에 인덱스를 걸지 않음

### 데이터 수집 서비스 - 로그 취합 서버
- 데이터 분석 서비스에서 나오는 로그는 보통 양이 엄청나고 데이터 형식이 제각각임
  - 이 데이터를 잘 취합해(aggregation) 소비하기 쉽게 만드렁야 함

### 데이터 수집 서비스 - 작업 서버
- 작업 서버(worker)는 주기적으로 비동기적 작업(job)을 실행하는 서버 집합
- 트라이 자료구조를 만들고 트라이 데이터베이스에 저장하는 역할을 담당

### 데이터 수집 서비스 - 트라이 캐시
- 트라이 캐시는 분산 캐시 시스템으로 트라이 데이터를 메모리에 유지해 읽기 연산 성능을 높이는 구실을 함
- 매주 트라이 DB의 스냅샷을 떠서 갱신

### 데이터 수집 서비스 - 트라이 DB
- 지속성 저장소
- 사용할 수 있는 선택지
  - 문서 저장소(document store)
    - 새 트라이를 매주 만드므로 주기적으로 트라이를 직렬화해 DB에 저장 가능
    - 몽고디비 같은 문서 저장소를 사용하면 편리함
  - key-value
    - 트라이는 해시 테이블 형태로 변환 가능
      - 트라이에 보관된 모든 접두어를 해시 테이블의 key로 변환
      - 각 트라이 노드에 저장된 모든 데이터를 해시 테이블 value로 변환
      - 각 노드가 하나의 <key, value> 쌍으로 변환

### 질의 서비스
- 사용자가 요청하면 [로드 밸런서 -> API 서버 -> 트라이 캐시 -> 트라이 DB] 를 거침
  - 검색 질의가 로드 밸런서로 전송
  - 로드밸런서가 해당 질의를 API 서버로 보냄
  - API 서버는 트라이 캐시에서 데이터를 가져와 해당 요청에 대한 자동완성 검색어 제한 응답을 구성
  - 데이터가 트라이 캐시에 없는 경우 DB에서 가져와 캐시를 채움
    - 캐시 미스는 캐시 서버의 메모리가 부족하거나 캐시 서버에 장애가 있어도 발생함
- 질의 서비스는 아주 빨라야 함.
  - AJAX 요청
    - 브라우저는 보통 AJAX 요청을 보내 자동완성된 검색어 목록을 가져옴
  - 브라우저 캐싱
    - 대부분 애플리케이션은 자동완성 검색어 제안 결과가 짧은 시간에 자주 바뀌지 않음
    - 이전에 제안된 검색어들을 브라우저 캐시에 넣어두면 빠르게 사용할 수 있다.
  - 데이터 샘플링
    - 대규모 시스템의 경우 모든 질의 결과를 로깅하도록 하면 CPU와 저장공간이 엄청나게 소진됨.
    - N개의 요청 가운데 1개만 로깅하도록하는 방법을 사용하면 유용함


### 트라이 연산
### 트라이 연산 - 트라이 생성
- 트라이 생성은 작업 서버가 담당하며, 데이터 분석 서비스의 로그나 DB로부터 취합된 데이터를 이용

### 트라이 연산 - 트라이 갱신
- 매주 1회 갱신
  - 새로운 트라이를 만든 후 기존 트라이를 대체
- 트라이의 각 노드를 개별적으로 갱신하는 방법
  - 성능이 좋지 않음
  - 트라이가 작을 경우에는 효율적일 수 있음.
  - 노드 갱신 시 상위 노드도 갱신해야함.

### 트라이 연산 - 검색어 삭제
- 혐오, 폭력성, 성적 등 위험한 질의어를 자동완성 결과에서 제거해야 함
- 트라이 캐시 앞에 필터 계층(filter layer)를 사용
- DB에서 해당 검색어 삭제는 다음 업데이트 사이클에 비동기로 진행하면 됨

### 규모 확장이 가능한 저장소
- 영어만 지원하면 되기에 첫 글자 기준으로 샤딩할 수 있음.
  - 다만, 각 알파벳에 해당하는 단어가 균등하지 않기에 균등 배분이 쉽지 않음
- 과거 질의 데이터의 패턴을 분석해 샤딩할 수 있음

## 4단계 - 마무리
- Q) 다국어 지원하려면 시스템을 어떻게 확장해야하는가?
  - 비영어권의 국가를 지원하려면 트라이에 유니코드 형태의 데이터를 저장해야 함.
- Q) 국가별로 인기 검색어 순위가 다를 경우?
  - 국가 별로 다른 트라이를 사용하고, 트라이를 CDN에 저장해 응답속도를 높일 수 있음.
- Q) 실시간으로 변하는 검색어의 추이를 반영하려면 어떡하는가?
  - 현 설계안에서는 적합하지 않음.
    - 작업 서버가 매주 1회 돌기에 적절하게 트라이 갱신이 어려움.
    - 트라이 구성에 너무 많은 시간이 소요됨.
  - 샤딩을 통해 작업 대상 데이터의 양을 줄임
  - 순위 모델(ranking model)을 바꿔 최근 검색어에 가중치 부여
  - 데이터가 스트림 형태로 올 수 있음.
    - 한 번에 모든 데이터를 동시에 사용할 수 없을 가능성이 존재함.
    - 데이터 스트리밍 -> 데이터가 지속적으로 생성됨.
      - 아파치 하둡 맵리듀스, 아파치 스파크 스트리밍, 아파치 스톰, 아파치 카프카 등의 시스템


### Q) 트라이가 트리 구조의 자료 구조인데, DB에 어떻게 저장할 수 있는가?
- 기존 RDB에는 저장하기 좋은 구조는 아님.
- 저장 시 몽고DB 같은 NoSQL을 사용함.

### 위 질문의 추가 논의 사항 : 무한 뎁스를 가질 수 있는 객체 형태일 경우 파싱하는 방법은?

### Q) 트리 구조 vs 인덱스 적용해 prefix 로 시작하는 모든 데이터를 정렬하면 비슷한 거 아닌가?
- SELECT * FROM table WHERE query LIKE `prefix%` ORDER BY query DESC LIMIT 5
- limit 5
  - 전체 다 가져오고 정렬
- 가져온 걸 orderby 정렬
- using filesort
  - 정렬 시 인덱스를 안 탐.
- like 의 성능 비효율
- 데이터가 0~10 99% 불균등 분포라면...?
- 옵티마이저
- 실행 계획이 의도대로 가지 않을 수 있음.


# 14장 - 유튜브 설계
- 유튜브의 통계 자료(2020년)
  - MAU : 20억
  - 매일 재생되는 비디오 수 : 50억
  - 미국 성인 중 73%가 이용
  - 크리에이터 : 5천만
  - 2019년 광고 수익 150억 달러
  - 모바일 인터넷 트래픽 점유율 37%
  - 80개 언어 지원

## 1단계 - 문제 이해 및 설계 범위 확정
- 유튜브는 비디오 외에도 댓글, 비디오 공유, 좋아요, 재생목록 저장, 구독 등 설계 범위가 너무 넓다.
- 설계 범위 구체화
  - Q) 어떤 기능이 가장 중요한가?
    - A) 비디오를 올리고 시청하는 기능
  - Q) 어떤 클라이언트를 지원하는가?
    - A) 모바일 앱, 웹 브라우저, 스마트 TV
  - Q) DAU는 몇 명인가?
    - A) 500만
  - Q) 평균 소비 시간은?
    - A) 30분
  - Q) 다국어 지원 여부?
    - A) 어떤 언어로도 사용가능해야 함
  - Q) 어떤 비디오 해상도를 지원?
    - A) 현존하는 비디오 종류와 해상도를 대부분 지원
  - Q) 암호화 필요?
    - A)  네
  - Q) 비디오 파일 크기 제한은?
    - A) 작은 비디오, 중간 크기 비디오에 초점을 맞춤. 비디오 최대 크기는 1GB로 제한
  - Q) 아마존이나 구글, MS에서 제공하는 클라우드 서비스를 활용해도 되는가?
    - A) Yes
- 설계 초점
  - 빠른 비디오 업로드
  - 원활한 비디오 재생
  - 재생 품질 선택 기능
  - 낮은 인프라 비용
  - 높은 가용성과 규모 확장성, 안정성
  - 지원 클라이언트
    - 모바일 앱, 웹 브라우저, 스마트 TV

### 개략적 규모 추정
- DAU : 500만
- 한 사용자는 하루 평균 5개의 비디오 시청
- 10% 사용자가 하루에 1개의 비디오 업로드
- 비디오 평균 크기는 300MB
- 비디오 저장을 위해 매일 새로 요구되는 저장 용량
  - 500만 * 10% * 300MB = 150TB
- CDN 비용
  - 클라우드 사용 시 CDN에서 나가는 데이터 양에 따라 과금
  - 아마존 CloudFront 사용 시 미국 기준 1GB 당 0.02달러 부과
  - 매일 발생하는 요금 : 150_000달러
    - 500만 * 5비디오 * 0.3GB * 0.02 달러
  - CDN을 통해 비디오 서비스 시 비용이 엄청남.


## 2단계 - 개략적 설계안 제시 및 동의 구하기
- CDN과 BLOB 스토리지는 기존 클라우드 서비스 활용
  - 시스템 설계 면접은 모든 것을 밑바닥부터 만드는 것과 관계 없음.
  - 주어진 시간 안에 적절한 기술을 골라 설계를 마치는 것이 더 중요함.
    - 예를 들어 BLOB 저장소를 쓸 것이라면 그것만 언급하고 어떻게 구현할지 상세 설계는 지나칠 수 있음.
  - 규모 확장이 쉬운 BLOB 저장소나 CDN을 만드는 것은 복잡하고 비용이 많이 들어 넷플릭스나 페이스북같은 큰 회사도 모든 것을 스스로 구축하지 않음.
- 단말
  - 컴퓨터, 모바일 폰, 스마트 TV 등을 통해 유튜브를 시청
- CDN
  - 비디오를 CDN에 저장하고, 재생 버튼을 누르면 CDN으로부터 스트리밍이 이루어짐
- API 서버
  - 비디오 스트리밍을 제외한 모든 요청은 API 서버가 처리
  - 피드 추천, 비디오 업로드 URL 생성, 메타 데이터 DB와 캐시 갱신 등

### 비디오 업로드 절차
- 사용자
  - 컴퓨터나 모바일 등으로 유튜브를 시청하는 이용자
- 로드밸런서
  - API 서버 각각으로 고르게 요청을 분산
- API 서버
  - 비디오 스트리밍을 제외한 다른 모든 요청을 처리
- 메타데이터 DB
  - 비디오의 메타데이터를 보관
  - 샤딩과 다중화를 적용해 성능과 가용성 요구사항을 충족
- 메타데이터 캐시
  - 성능을 높이기 위해 비디오 메타데이터와 사용자 객체(user object)는 캐시함
- 원본 저장소
  - 원본 비디오를 저장할 대형 이진 파일 저장서(BLOB, Binary Large Object storage)
- 트랜스 코딩 서버(transcoding server)
  - 비디오 트랜스코딩은 비디오 인코딩이라 부리기도 함.
  - 비디오 포맷 변환 절차
  - 단말이나 대역폭 요구 사항에 맞는 최적의 비디오 스트림을 제공하기 위해 필요
- 트랜스코딩 비디오 저장소(transcoded storage)
  - 트랜스코딩이 완료된 비디오를 저장하는 BLOB 저장소
- CDN
  - 비디오를 캐시하는 역할을 담당
- 트랜스코딩 완료 큐
  - 비디오 트랜스코딩 완료 이벤트들을 보관할 메시지 큐
- 트랜스코딩 완료 핸들러
  - 트랜스코딩 완료 큐에서 이벤트 데이터를 꺼내 메타 데이터 캐시와 DB를 갱신할 작업 서버
- 비디오 업로드는 업로드와 메타 데이터 갱신이 병렬적으로 수행됨.
  - 메타데이터에는 비디오 URL, 크기, 해상도, 포맷, 사용자 정보 등이 포함됨.

### 프로세스 a : 비디오 업로드
- 비디오를 원본 저장소에 업로드
- 트랜스코딩 서버는 원본 저장소에서 해당 비디오를 가져와 트랜스코딩을 시작
- 트랜스코딩이 완료되면 아래 두 절차가 병렬저긍로 수행됨
  - 완료된 비디오를 트랜스코딩 비디오 저장소로 업로드
  - 트랜스코딩 완료 이벤트를 트랜스코딩 완료 큐에 넣음
    - 트랜스코딩이 끝난 비디오를 CDN에 올림
    - 완료 핸들러가 이벤트 데이터를 큐에서 꺼냄
    - 완료 핸들러가 메타 데이터 DB와 캐시를 갱신
- API 서버가 단말에게 비디오 업로드가 끝나서 스트리밍 준비가 되었음을 알림

### 프로세스 b : 메타데이터 갱신
- 원본 저장소에 파일이 업로드 되는 동안 단말은 병렬저긍로 비디오 메타데이터 갱신 요청을 API 서버에 보냄
- API 서버는 이 정보를 메타데이터 캐시와 DB에 업데이트함

### 비디오 스트리밍 절차
- 스트리밍 프로토콜
  - 비디오 스트리밍을 위해 데이터 전송 시 쓰이는 표준화된 통신 방법
  - MPEG-DASH
    - MPEG : Moving Picture Experts Group
    - DASH : Dynamic Adaptive Streaming over HTTP
  - 애플 HLS
    - HTTP Live Streaming
  - MS 스무스 스트리밍
  - 어도비 HTTP 동적 스트리밍
- 비디오는 CDN에서 바로 스트리밍됨.
  - 사용자 단말에서 가장 가까운 CDN 엣지 서버가 비디오 전송을 담당함
  - 전송지연이 아주 낮음

## 3단계 - 상세 설계
### 비디오 트랜스코딩
- 비디오는 보통 특정 포맷으로 저장됨.
- 다른 단말에서도 재생하기 위해서는 다른 단말과 호환되는 비트레이트(bitrate)와 포맷으로 저장되어야 함.
  - 비트레이트는 비디오를 구성하는 비트가 얼마나 빨리 처리되어야 하는지를 나타내는 단위
  - 비트레이트가 높은 비디오는 일반적으로 고화질 비디오임
  - 비트레이트가 높은 비디오 스트림을 정상 재생하려면 높은 성능의 컴퓨팅 파워가 필요하고, 인터넷 속도가 빨라야 함
- 비디오 트랜스코딩이 중요한 이유
  - 가공되지 않은 원본 비디오는 저장 공간을 많이 차지함
  - 상당수의 단말과 브라우저는 특정 종류의 비디오 포맷만 지원
    - 호환성 문제 해결을 위해 하나의 비디오를 여러 포맷으로 인코딩해두는 것이 좋음
  - 네트워크 대역폭에 따라 다른 화질의 비디오를 제공해야 끊김이 없음
  - 모바일 단말은 네트워크 상황이 수시로 달라질 수 있음.
    - 화질을 자동으로 변경하거나 수동으로 변경할 수 있게 해야함.
- 인코딩 포맷은 아주 다양함
  - 컨테이너
    - 비디오 파일, 오디오, 메타데이터를 담는 바구니 같은 것임
    - avi, mov, mp4 등의 파일 확장자
  - 코덱
    - 비디오 화질은 보존하면서 파일 크기를 줄이기 위해 고안된 압축/압축 해제 알고리즘

### 유향 비순환 그래프(DAG) 모델
- 비디오 트랜스코딩은 컴퓨팅 자원과 시간이 많이 듦
- 사용자마다 워터마크, 섬네일 등 여러 요구사항이 존재할 수 있음.
- 사용자가 원하는 각기 다른 유형의 비디오 프로세싱 파이프라인을 지원하며 병렬처리를 높이기 위해 적절한 수준의 추상화를 도입해서 실행할 작업을 정의할 수 있게 해야함.
- DAG 모델 도입 시 유연성과 병렬성을 달성할 수 있다.
- 비디오, 오디오, 메타데이터 세 부분으로 나뉘어 처리됨.
  - 검사
    - 좋은 품질의 비디오인지, 손상은 없는지 확인하는 작업
  - 비디오 인코딩
    - 비디오를 다양한 해상도, 코덱, 비트레이트 조합으로 인코딩하는 작업
  - 섬네일
    - 사용자가 업로드한 이미지나 비디오에서 자동 추출된 이미지로 섬네일을 만드는 작업
  - 워터 마크
    - 비디오에 대한 식별정보를 이미지 위에 오버레이 형태로 띄워 표시하는 작업

### 비디오 트랜스코딩 아키텍처 - 전처리기
- 비디오 분할
  - 비디오 스트림을 GOP(Group of Pictures)라고 불리는 단위로 쪼갬
    - GOP는 특정 순서로 배열된 프레임 그룹
    - 하나의 GOP는 독립적으로 재생 가능, 길이는 보통 몇 초 정도
    - 오래된 단말이나 브라우저는 GOP 단위의 분할을 지원하지 않음.
      - 그런 단말은 전처리기가 비디오 분할을 대신함
  - DAG 생성
    - 클라이언트 프로그래머가 작성한 설정 파일에 따라 DAG를 만들어냄.
  - 데이터 캐시
    - 전처리기는 분할된 비디오의 캐시이기도 함
    - 안정성을 높이기 위해 전처리기는 GOP와 메타데이터를 임시 저장소(temporary storage)에 보관
    - 비디오 인코딩이 실패하면 시스템은 이렇게 보관된 데이터를 활용해 인코딩을 재개

### 비디오 트랜스코딩 아키텍처 - DAG 스케줄러
- DAG 스케줄러는 DAG 그래프를 몇 단계로 분할한 다음 각각을 자원 관리자의 작업 큐에 집어넣음

### 비디오 트랜스코딩 아키텍처 - 자원 관리자
- 자원 관리자는 자원 배분을 효과적으로 수행하는 역할을 담당
- 작업 큐
  - 실행할 작업이 보관되어 있는 우선순위 큐
- 작업 서버 큐
  - 작업 서버의 가용 상태 정보가 보관되어 있는 우선순위 큐
- 실행 큐
  - 현재 실행 중인 작업 및 작섭 서버 정보가 보관되어 있는 큐
- 작업 스케줄러
  - 최적의 작업/서버 조합을 골라 작업을 수행하도록 지시
  - 작업 관리자는 작업 큐에서 가장 높은 우선순위의 작업을 꺼냄
  - 해당 작업을 실행하기 적합한 작업 서버를 고름
  - 해당 작업 서버에게 작업 스케줄러가 작업 실행을 지시
  - 해당 작업이 어떤 서버에 할당되었는지에 대한 정보를 실행 큐에 넣음
  - 작업이 완료되면 해당 작업을 실행 큐에서 제거

### 비디오 트랜스코딩 아키텍처 - 작업 서버
- 작업 서버는 DAG에 정의된 작업을 수행

### 비디오 트랜스코딩 아키텍처 - 임시 저장소
- 임시 저장소 구현에는 여러 저장소 시스템을 활용할 수 있음.
- 시스템에 따라 데이터 유형, 크기, 빈도 등이 다 달라짐
- 예를 들어 메타데이터는 자주 참조하고 크기가 작으므로 메모리에 캐시해두는 것이 좋다.


### 시스템 최적화 - 속도 최적화 : 비디오 병렬 업로드
- 하나의 비디오는 작은 GOP로 분할해 병렬적으로 업로드함.
  - 병렬적으로 업로드 시 일부가 실패해도 빠르게 업로드를 재개할 수 있음.

### 시스템 최적화 - 속도 최적화 : 업로드 센터를 사용자 근거리에 지정
- 업로드 센터를 여러 곳에 두면 속도를 개선할 수 있음.
- CDN을 업로드 센터로 이용하면 속도 개선 가능함

### 시스템 최적화 - 속도 최적화 : 모든 절차를 병렬화
- 낮은 응답지연을 달성하는 것은 어려운 일임
- 느슨하게 결합된 시스템을 만들어서 병렬성을 높이는 것도 좋은 방법임
- 기존 설계안은 이전 단계 결과물을 입력해 다음 결과물로 만들어내기에 의존성이 높아 병렬성을 높이기 어려움.
  - 메시지 큐를 도입해 시스템 결합도를 낮출 수 있음.
  - 메시지 큐 도입 전 인코딩 모듈은 다운로드 모듈의 작업이 끝나기를 기다려야 함
  - 메시지 큐 도입 후 인코딩 모듈은 다운오륻 모듈의 작업이 끝나기를 기다릴 필요가 없음.
    - 메시지 큐에 보관된 이벤트 각각을 인코딩 모듈은 병렬적으로 처리할 수 있음.

### 시스템 최적화 - 안전성 최적화 : 미리 사인된 업로드 URL
- 허가 받은 사용자만 올바른 장소에 비디오를 업로드할 수 있도록 pre-signed 업로드 URL을 이용함
  - 클라이언트는 HTTP 서버에 POST 요청을 해 pre-signed URL을 받음
    - 해당 URL이 가리키는 객체에 대한 접근 권한은 이미 주어짐.
  - API 서버는 pre-signed URL을 반환함
  - 클라이언트는 해당 URL의 위치에 비디오를 업로드함

### 시스템 최적화 - 안전성 최적화 : 비디오 보호
- 비디오 저작권 보호
  - 디지털 저작권 관리(DRM: Digital Rights Management) 시스템 도입
    - 가장 널리 사용되는 시스템, 애플의 페어플레이, 구글의 와이드바인, SM 플레이레디 등이 있음
  - AES 암호화
    - 비디오를 암호화하고 접근 권한을 설정하는 방식
    - 암호화된 비디오는 재생 시에만 복호화함
    - 허락된 사용자만 암호화된 비디오를 시청할 수 있음
  - 워터마크
    - 비디오 위에 소유자 정보를 포함하는 이미지 오버레이를 올리는 것임

### 비용 최적화
- CDN은 핵심 부분이지만 가격이 데이터 크기에 비례해서 커짐
- 인기 비디오는 CDN을 통해 재생하고, 인기 없는 비디오는 비디오 서버를 통해 재생
- 인기 없는 비디오는 인코딩 할 필요가 없을 수도 있음. 짧은 비디오는 필요 시 인코딩해 재생 가능
- 어떤 비디오는 지역성이 있을 수 있음. 이런 비디오는 다른 지역에 옮길 필요가 없음
- CDN을 직접 구축 후 인터넷 서비스 제공자(ISP)와 제휴
  - CDN을 직접 구축하는 것은 초대형 프로젝트임

### 오류 처리
- 회복 가능 오류
  - 특정 비디오 세그먼트를 트랜스코딩하다 실패했다던가 하는 오류 등
  - 몇 번 재시도하면 일반적으로는 해결 됨
  - 계속 실패해서 복구가 어려울 경우엔 클라이언트에 오류 코드를 반환
- 회복 불가능 오류
  - 비디오 포맷이 잘못되거나 하는 등의 회복 불가능 오류
  - 해당 비디오에 대한 작업을 중단하고 클라이언트에게 적절한 오류 코드를 반환
- 전형적인 해결 방법
  - 업로드 오류
    - 몇 회 재시도
  - 비디오 분할 오류
    - 낡은 버전의 클라이언트가 GOP 경계에 따라 분할하지 못하면 전체 비디오를 서버에 전송하고 서버가 해당 비디오를 분할 처리
  - 트랜스코딩 오류
    - 재시도함
  - 전처리 오류
    - DAG 그래프를 재생성
  - DAG 스케줄러 오류
    - 작업을 다시 스케줄링
  - 작업 관리자 큐에 장애 발생
    - 사본을 이용
  - 작업 서버 장애
    - 다른 서버에 해당 작업을 재시도
  - API 서버 장애
    - API 서버는 무상태 서버이므로 신규 요청은 다른 API 서버로 우회
  - 메타데이터 캐시 서버 장애
    - 데이터는 다중화되어 있으므로 다른 노드에서 데이터를 여전히 가져올 수 있음
    - 장애난 캐시 서버는 새로운 것으로 교체
  - 메타데이터 DB 서버 장애
    - 주 서버 사망 시 부 서버 가운테 하나를 주 서버로 교체
    - 부 서버가 죽으면 다른 부 서버를 통해 읽기 연산을 처리하고 죽은 서버는 새 것으로 교체

## 4단계 - 마무리
- 추가 논의 사항
  - API 계층의 규모 확장성 확보 방안
    - API 서버는 무상태 서버이므로 수평적 규모 확장이 가능
  - DB 계층의 규모 확장성 확보 방안
    - DB 다중화와 샤딩
  - 라이브 스트리밍
    - 실시간 비디오 스트리밍
    - 비-라이브 스트리밍과 유사함.
    - 비-라이브와 차이점
      - 응답 지연이 더 낮아야함 -> 프로토콜 선정에 유의함
      - 병렬화 필요성이 떨어짐
      - 작은 단위의 데이터를 실시간으로 빨리 처리해야 함
      - 오류 처리 방법을 달리해야 함. 너무 많은 시간이 걸리는 방안은 사용하기 어려움
  - 비디오 삭제
    - 저작권을 위반하거나 선정적이거나 불법적인 비디오 등은 삭제해야 함.
    - 업로드 과정에서 식별할 수도 있지만, 사용자의 신고 절차를 통해 판별할 수도 있음.

### Q) 작업에 대한 정보를 저장할 때 큐에 저장하는 이유가 무엇인가? -> 실행 중인 작업과 서버에 대한 정보이므로 key-value 값이니까 해쉬 테이블 등에 넣어두는 것은 어떤가?
- 해쉬 테이블의 단점을 위주로 사용하지 않은 이유를 추적해보자
  - 해쉬 테이블은 키-값 쌍을 저장하는 자료구조로, 키를 해싱하여 값을 찾는 방식을 사용함.
  - 정렬에 단점이 있음.
  - 우선 순위를 저장할수야 있겠지만, 우선 순위에 따른 처리가 어려움.
  - 또한, 우선 순위에 대해서 복잡한 처리가 들어갈 경우 해쉬 테이블은 적합하지 않음.


# 15장 - 구글 드라이브 설계
- 구글 드라이브
  - 파일 저장 및 동기화 서비스, 문서, 사진 비디오 등의 파일을 클라우드에 보관할 수 있도록 함.
  - 해당 파일은 컴퓨터, 스마트폰 등 어떤 단말에서도 이용 가능해야 함.

## 1단계 - 문제 이해 및 설계 범위 확정
- 요구 사항 확정
  - Q) 가장 중요하게 지원해야하는 기능은?
    - A) 파일 업로드/다운로드, 파일 동기화, 알림
  - Q) 모바일 앱이나 웹 앱 하나만 하면되는지, 둘 다해야하는지?
    - A) 둘 다
  - Q) 파일은 암호화하는가?
    - A) 네
  - Q) 파일 크기 제한은?
    - A) 10GB
  - Q) 사용자는 얼마나 되는가?
    - A) DAU 천만명
- 집중할 기능
  - 파일 추가
    - 가장 쉬운 방법은 drag-and-drop
  - 파일 다운로드
  - 여러 단말에서 파일 동기화
  - 파일 갱신 이력 조회
  - 파일 공유
  - 파일이 편집되거나 삭제되거나 새롭게 공유되었을 때 알림 표시
- 논의하지 않을 내용
  - 구글 문서 편집 및 협업 기능
    - 여러 사용자가 동시에 편집하는 기능 제외
- 비 기능적 요구 사항
  - 안정성
    - 데이터 손실이 있어선 안됨
  - 빠른 동기화 속도
  - 네트워크 대역폭
    - 네트워크를 불필요하게 많이 사용하면 안됨
  - 규모 확장성
  - 높은 가용성

### 개략적 추정치
- 가입 유저는 5000만
- DAU 천만으로 가정
- 모든 사용자에게 10GB 무료 제공
- 매일 각 사용자가 평균 2개의 파일 업로드 가정
  - 각 파일의 평균 크기는 500Kb
- 읽기:쓰기 비율은 1:1
- 필요한 저장 공간 총량 500Pb
  - 5000만 user * 10GB
- 업로드 API QPS 240
  - 1000만 user * 2회 업로드/24시간/3600초
- 최대 QPS 480
  - QPS * 2

## 2단계 - 개략적 설계안 제시 및 동의 구하기
### 우선 서버 한대부터 점진적으로 발전
- 파일을 올리고 다운로드 하는 과정을 처리할 웹 서버
- 메타데이터를 저장할 DB
- 파일을 저장할 저장소 시스템
  - drive/ 라는 디렉토리를 만들고 각 유저 네임스페이스에 사용자 파일을 저장

### API - 1. 파일 업로드 API
- 단순 업로드
  - 파일 크기가 작을 때 사용
- 이어 올리기
  - 파일 크기가 크고 네트워크 문제로 업로드 중단 가능성이 높을 때 사용
  - files/upload
  - 인자
    - uploadType=resumable
    - data : 업로드할 로컬 파일
  - 절차
    - 이어올리기 URL을 받기 위한 최초 요청
    - 데이터를 업로드하고 업로드 상태 모니터링
    - 업로드에 장애 발생 시 장애 발생시점부터 업로드를 재시작

### API - 2. 파일 다운로드 API
- files/download
- 인자
  - path : 다운로드할 파일의 경로
    - { "path" : "/recipes/soup/best_soup.txt" }

### API - 3. 파일 갱신 히스토리 API
- files/list_revisions
- 인자
  - path : 갱신 히스토리를 가져올 파일의 경로
  - limit : 20
  - { "path" : "/recipes/soup/best_soup.txt", "limit": 20 }


지금까지 나열한 모든 API는 사용자 인증을 사용하고 HTTPS 프로토콜을 사용해야 함.
SSL을 사용하는 이유는 클라와 백엔드 서버가 주고받는 데이터를 보호하기 위한 것

### 한 대 서버의 제약 극복
- 업로드 파일이 많아지면 파일 시스템이 가득차게 됨.
- 샤딩을 통해 해결할 수 있다.
- 하지만, 이는 수동적이고 앞으로도 발생할 수 있다.
  - 앞으론 AWS S3를 사용한다. 

### 동기화 충돌
- 여러 사용자가 동시에 같은 파일을 갱신할 경우 동기화 충돌이 발생함
- 오류 발생 시점에 시스템에는 같은 파일의 두 가지 버전이 존재함
  - 로컬 사본과 서버에 있는 최신 버전
  - 사용자는 이 두 파일을 하나로 합칠지, 둘 중 하나를 다른 파일로 대체할지를 결정해야 함.

### 개략적 설계안
- 사용자 단말
  - 사용자가 이용하는 웹 브라우저나 모바일 앱 등의 클라이언트
- 블록 저장소 서버(block server)
  - 파일 블록을 클라우드 저장소에 업로드하는 서버
  - 파일을 여러 블록으로 나누어 저장
  - 각 블록에는 고유한 해시값이 할당됨
  - 해시 값은 메타 데이터 DB에 저장됨
  - 각 블록은 독립적인 객체로 S3에 보관
  - 파일 재구성 시 블록을 원래 순서대로 합쳐야함
- 클라우드 저장소
  - 파일은 블록 단위로 나눠져 클라우드 저장소에 보관
- 아카이빙 저장소
  - 오랫동안 사용되지 않은 비활성(inactive) 파일을 보관
- 로드밸런서
  - 요청을 모든 API 서버에 고르게 분산
- API 서버
  - 파입 업로드 외 모든 것을 담당
- 메타데이터 DB
  - 메타 데이터 정보를 보관
    - 사용자, 파일, 블록, 버전
  - 실제 파일은 클라우드에 저장되며, 메타 데이터만 DB에 저장
- 메타데이터 캐시
  - 성능을 높이기 위해 자주 사용되는 메타 데이터를 캐시
- 알림 서비스
  - 이벤트 발생 시 사용자에게 알림을 보냄
  - 발생/구독 프로토콜 기반 시스템
  - 파일 추가, 편집, 삭제, 파일 최신 상태 알림 등에 사용
- 오프라인 사용자 백업 큐(offline backup queue)
  - 클라이언트가 접속 중이 아니라 파일 최신 상태 확인이 안될 때 큐에 두고 클라이언트가 접속했을 때 동기화함

## 3단계 - 상세 설계
### 블록 저장소 서버
- 정기적으로 갱신되는 큰 파일은 업데이트마다 전체 파일을 서버로 보내면 네트워크 대역폭을 많이 사용함.
- 델타 동기화(delta sync)
  - 파일 수정 시 수정된 블록만 동기화
- 압축(compression)
  - 블록 단위로 압축 시 데이터 크기를 줄일 수 있음
  - 파일 유형에 따라 알고리즘 변경
    - 텍스트 파일 압축 시 gzip, bzip2를 사용
    - 이미지나 비디오에는 다른 알고리즘 사용
- 주어진 파일을 작은 블록들로 분할
- 각 블록을 압축
- 클라우드 저장소로 보내기 전 암호화
- 클라우드 저장소로 전송

### 높은 일관성 요구사항
- 해당 시스템은 강한 일관성을 기본으로 지원해야 함
- 같은 파일이 단말이나 사용자에 따라 다르게 보이는 것을 허용하지 않음.
- 메타데이터 캐시와 DB 계층에도 같은 원칙이 적용됨
- 메모리 캐시는 보통 최종 일관성(eventual consistency)을 지원함
  - 캐시에 보관된 사본과 DB의 원본이 일치해야 함
  - DB에 보관된 원본에 변경이 있으면 캐시의 사본을 무효화
- RDB는 ACID를 보장하므로 강한 일관성 보장이 쉬움
- NoSQL은 기본적으로 지원하지 않아서 동기화 로직 안에 프로그램해 넣어야 함.

### 메타데이터 DB
- user
  - 이름, 이메일, 프로필 사진 등
  - 사용자와 관계된 기본적 정보들 보관
- device
  - 단말 정보 보관
  - push_id는 모바일 푸시 알림을 위한 것
- namespace
  - 사용자의 루트 디렉토리 정보 보관
- file
  - 파일의 최신 정보 보관
- file_version
  - 파일의 갱신 이력 보관
  - 전부 읽기 전용 레코드
    - 갱신 이력 훼손을 방지
- block
  - 파일 블록에 대한 정보 보관
  - 파일 블록을 올바른 순서로 조합 시 특정 버전의 파일 복원 가능

### 업로드 절차
- 파일 메타데이터 추가
  - 클라 1이 새 파일의 메타데이터 추가를 위해 요청 전송
  - 새 파일의 메타데이터를 DB에 저장하고 업로드 상태를 대기중(panding)으로 표시
  - 새 파일이 추가되었음을 알림 서비스에 통지
  - 알림 서비스는 관련된 클라(클라 2)에게 파일 업로드를 알림
- 파일을 클라우드 저장소에 업로드
  - 클라 1이 파일을 블록 저장소에 업로드
  - 블록 저장소 서버는 파일을 블록 단위로 쪼갠 다음 압축하고 암호화해 클라우드 저장소에 전송
  - 업로드 후 클라우드 스토리지는 완료 콜백을 API 서버로 호출
  - 메타데이터 DB에 저장된 해당 파일의 상태를 완료(uploaded)로 변경
  - 알림 서비스에 파일 업로드 완료를 통지
  - 알림 서비스는 관련된 클라(클라 2)에게 파일 업로드 완료를 알림
- 파일 수정의 흐름도 위와 유사함

### 다운로드 절차
- 다른 클라가 파일을 편집하거나 추가했다는 걸 감지하는 방법
  - 클라 A가 접속 중이고 다른 클라가 파일 변경 시 알림 서비스가 클라 A에게 알림을 보냄
  - 클라 A가 비연결 상태일 때 데이터는 캐시에 보관. 해당 클라가 접속 시 새 버전으로 업데이트
- 파일 변경 감지 시 파일 재구성
  - 알림 서비스가 클라에게 파일 변경을 알림
  - 알림 확인 후 클라가 새로운 메타데이터 요청
  - API 서버는 메타데이터 DB에게 새 메타데이터 요청
  - API 서버에는 새 메타데이터 반환
  - 클라에게 새 메타데이터 반환
  - 클라는 새 메타데이터를 받는 즉시 블록 다운로드 요청 전송
  - 블록 저장소 서버는 클라우드 저장소에서 블록 다운로드
  - 클라우드 저장소는 블록 서버에 요청된 블록 반환
  - 블록 저장소 서버는 클라에게 요청된 블록을 반환
  - 클라는 전송된 블록을 사용해 파일 재구성

### 알림 서비스
- 파일 일관성을 위해 파일 수정 시 다른 클라에게 이를 알려서 충돌을 줄여야함.
- 알림 보내는 방법
  - 롱 폴링
    - 양방향 통신이 필요치 않음
  - 웹소켓
    - 실시간 양방향 통신이 요구되는 채팅같은 경우 필요

### 저장소 공간 절약
- 갱신 이력 보존과 안정성을 위해 파일의 여러 버전을 여러 데이터센터에 저장할 필요가 있음.
- 저장 공간이 많이 필요함.
- 비용 절감
  - 중복 제거(de-dupe)
    - 중복된 파일 블록을 계정 차원에서 제거
    - 중복 여부는 해시 값을 비교해 판단
  - 지능적 백업 전략 도입
    - 한도 설정
      - 보관할 파일 버전에 상한을 두고, 오래된 버전을 제거
    - 중요한 버전만 보관
      - 잦은 변경이 있는 등의 경우 중요한 버전만 보관
  - 아카이빙 저장소
    - 자주 사용되지 않는 것들은 아카이빙

### 장애 처리
- 대규모 시스템은 피할수 없음
- 로드밸런서 장애
  - 로드밸런서 장애 시 서브 로드밸런서가 활성화되어 트래픽을 받아야 함.
  - 로드밸런서 끼리는 보통 박동 신호를 주기적으로 보내서 모니터링함
- 블록 저장소 서버 장애
  - 블록 저장소 장애 시 다른 서버가 미완료 상태 또는 대기 상태인 작업을 이어야함
- 클라우드 저장소 장애
  - S3 버킷은 다중화되어 있으므로 다른 지역에서 파일을 가져옴
- API 서버 장애
  - 무상태 서버이므로 서버 장애 시 로드밸런서를 통해 다른 서버로 트래픽을 이전
- 메타데이터 캐시 장애
  - 메타데이터 캐시도 다중화함.
  - 장애 시 다른 노드에서 데이터를 가져옴
- 메타데이터 DB 장애
  - 주 서버가 죽으면 부 서버 중 하나를 주 서버로 승격
  - 부 서버가 죽으면 다른 부 서버를 통해 읽기 연산을 처리하고 죽은 서버는 새 것으로 교체
- 알림 서비스 장애
  - 접속 중인 모든 사용자는 알림 서버와 롱 폴링을 함.
  - 다른 서버로 이전해 롱 폴링 연결을 복구해야 함
- 오프라인 사용자 백업 큐 장애
  - 큐 또한 다중화해야함.
  - 장애 발생 시 구독 중인 클라는 다른 백업 큐로 구독 관계를 재설정


## 4단계 - 마무리
- 블록 저장소 서버를 거치지 않고 클라우드 저장소에 다이렉트 업로드
  - 업로드가 빠름
  - 단점
    - 분할/압축/암호화 등의 작업을 클라이언트에서 해야함
    - 플랫폿별로 따로 구현해야 함
    - 클라이언트 해킹 가능성 존재.
      - 암호화 로직을 클라에 두는 것은 적절하지 않음.
- 접속 상태를 관리하는 로직을 별도 서비스로 이전
  - 알림 서비스에서 관련 로직 분리 시 다른 서비스에서도 쉽게 활용 가능

### Q) 메타데이터와 파일을 분리하는 이유가 무엇인가?
- 어디 저장했는지 알아야 함
- 파일이 분할되어 있을 때 메타데이터에 작성되어 있으면 유리함
- 오래된 이미지 파일 제거 시 유리
- 메타 데이터 변경 시 파일 전체를 변경하는 것이 아니라 RDB 상의 메타 데이터만 변경하면 됨
- 운영하고 있는 서비스와 연계성에서 유리함.
  - S3에 메타 데이터 보관 시 검색이나 분석 등에서 사용하기 어려울 수 있음

### Q) 구글 드라이브에서 동기화 문제 발생 시 구글 드라이브에서 해결했는가?
- 낙관적 락처럼 버전 정보가 있음.
  - 이를 바탕으로 버전 정보를 비교해서 충돌 여부를 판단
  - 이후 사용자가 선택하게 함.